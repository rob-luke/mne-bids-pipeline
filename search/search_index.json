{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"What is the MNE-BIDS-Pipeline? \u00b6 The MNE-BIDS-Pipeline is a full-flegded processing pipeline for your MEG and EEG data. It operates on raw data stored according to the Brain Imaging Data Structure (BIDS). Processing is controlled using a simple human-readable configuration file. Learn more Get started","title":"Home"},{"location":"index.html#what-is-the-mne-bids-pipeline","text":"The MNE-BIDS-Pipeline is a full-flegded processing pipeline for your MEG and EEG data. It operates on raw data stored according to the Brain Imaging Data Structure (BIDS). Processing is controlled using a simple human-readable configuration file. Learn more Get started","title":"What is the MNE-BIDS-Pipeline?"},{"location":"changes.html","text":"Changes since April 15, 2021 \u00b6 New features & enhancements \u00b6 The new configuration option ica_reject allows to exclude epochs from the ICA fit based on peak-to-peak amplitude. An official project governance structure has officially been adopted. Drastically reduces memory usage when creating epochs from datasets with multiple runs. ( #355 by Richard H\u00f6chenberger ) Behavior changes \u00b6 The conditions setting will now be None by default. It is a required setting so it will raise an error if left as None . ( #348 by (' Julia Guiomar Niso Gal\u00e1n ', ' Richard H\u00f6chenberger ')) Epochs rejection based on peak-to-peak amplitude, as controlled via the reject setting, will now take place after ICA or SSP. In previous versions of the Pipeline, rejection was carried out before ICA and SSP. The exclude epochs from ICA fitting, use the new ica_reject setting. We don't apply SSP by default anymore. ( #315 by Richard H\u00f6chenberger ) The use_ssp and use_ica settings have been removed. Please use the new spatial_filter setting instead. ( #315 by Richard H\u00f6chenberger ) The allow_maxshield setting has been removed. The Pipeline now automatically ensures that FIFF files of recordings with active shielding (MaxShield) can be imported. Later stages of the Pipeline will fail if Maxwell filtering of such data is disabled via use_maxwell_filter=False . ( #318 by Richard H\u00f6chenberger ) The overlay plots that show the effects of ICA cleaning are now based on the baseline-corrected data to make it easier to spot the differences. ( #320 by Richard H\u00f6chenberger ) bids_root and deriv_root are now converted to absolute paths to avoid running into issues caused by relative path specifications. ( #322 by Richard H\u00f6chenberger ) Warn if using ICA and no EOG- or ECG-related ICs were detected. ( #351 by ) config.crop has been renamed to the more explicit config.crop_runs , as it only applies to individual runs and not the concatenated data. ( #358 by Richard H\u00f6chenberger ) Bug fixes \u00b6 The FreeSurfer script could only be run if --n_jobs was passed explicitly ( #287 by Merlin Dumeur ) Fix a problem with the FreeSurfer processing step that caused the error message Could not consume arg after completion ( #301 by Richard H\u00f6chenberger ) Selecting the extended_infomax ICA algorithm caused a crash ( #308 by Richard H\u00f6chenberger ) Correctly handle eog_channels = None setting after creation of bipolar EEG channels ( #311 by Richard H\u00f6chenberger ) Added instructions on how to handle FileNotFoundError when loading the BEM model in the source steps ( #304 by Merlin Dumeur ) When using find_noisy_channels_meg or find_flat_channels_meg , we now pass mf_head_origin to the respective bad channel detection algorithm to achieve better performance ( #319 by Alex Gramfort ) Baseline was not applied to epochs if neither ICA nor SSP was used ( #319 by Richard H\u00f6chenberger ) Ensure we always use the cleaned epochs for constructing evoked data ( #319 by Alex Gramfort ) The summary report didn't use the cleaned epochs for showing the effects of ICA. ( #320 by Richard H\u00f6chenberger ) The sanity check comparing the rank of the experimental data and the rank of the empty-room after Maxwell-filtering did not use the maxfiltered data. ( #336 by Alex Gramfort , Richard H\u00f6chenberger , and ) epochs_tmin and epochs_tmax were named incorrectly in some test config files. ( #340 by )","title":"What's new"},{"location":"changes.html#changes-since-april-15-2021","text":"","title":"Changes since April 15, 2021"},{"location":"changes.html#new-features-enhancements","text":"The new configuration option ica_reject allows to exclude epochs from the ICA fit based on peak-to-peak amplitude. An official project governance structure has officially been adopted. Drastically reduces memory usage when creating epochs from datasets with multiple runs. ( #355 by Richard H\u00f6chenberger )","title":"New features &amp; enhancements"},{"location":"changes.html#behavior-changes","text":"The conditions setting will now be None by default. It is a required setting so it will raise an error if left as None . ( #348 by (' Julia Guiomar Niso Gal\u00e1n ', ' Richard H\u00f6chenberger ')) Epochs rejection based on peak-to-peak amplitude, as controlled via the reject setting, will now take place after ICA or SSP. In previous versions of the Pipeline, rejection was carried out before ICA and SSP. The exclude epochs from ICA fitting, use the new ica_reject setting. We don't apply SSP by default anymore. ( #315 by Richard H\u00f6chenberger ) The use_ssp and use_ica settings have been removed. Please use the new spatial_filter setting instead. ( #315 by Richard H\u00f6chenberger ) The allow_maxshield setting has been removed. The Pipeline now automatically ensures that FIFF files of recordings with active shielding (MaxShield) can be imported. Later stages of the Pipeline will fail if Maxwell filtering of such data is disabled via use_maxwell_filter=False . ( #318 by Richard H\u00f6chenberger ) The overlay plots that show the effects of ICA cleaning are now based on the baseline-corrected data to make it easier to spot the differences. ( #320 by Richard H\u00f6chenberger ) bids_root and deriv_root are now converted to absolute paths to avoid running into issues caused by relative path specifications. ( #322 by Richard H\u00f6chenberger ) Warn if using ICA and no EOG- or ECG-related ICs were detected. ( #351 by ) config.crop has been renamed to the more explicit config.crop_runs , as it only applies to individual runs and not the concatenated data. ( #358 by Richard H\u00f6chenberger )","title":"Behavior changes"},{"location":"changes.html#bug-fixes","text":"The FreeSurfer script could only be run if --n_jobs was passed explicitly ( #287 by Merlin Dumeur ) Fix a problem with the FreeSurfer processing step that caused the error message Could not consume arg after completion ( #301 by Richard H\u00f6chenberger ) Selecting the extended_infomax ICA algorithm caused a crash ( #308 by Richard H\u00f6chenberger ) Correctly handle eog_channels = None setting after creation of bipolar EEG channels ( #311 by Richard H\u00f6chenberger ) Added instructions on how to handle FileNotFoundError when loading the BEM model in the source steps ( #304 by Merlin Dumeur ) When using find_noisy_channels_meg or find_flat_channels_meg , we now pass mf_head_origin to the respective bad channel detection algorithm to achieve better performance ( #319 by Alex Gramfort ) Baseline was not applied to epochs if neither ICA nor SSP was used ( #319 by Richard H\u00f6chenberger ) Ensure we always use the cleaned epochs for constructing evoked data ( #319 by Alex Gramfort ) The summary report didn't use the cleaned epochs for showing the effects of ICA. ( #320 by Richard H\u00f6chenberger ) The sanity check comparing the rank of the experimental data and the rank of the empty-room after Maxwell-filtering did not use the maxfiltered data. ( #336 by Alex Gramfort , Richard H\u00f6chenberger , and ) epochs_tmin and epochs_tmax were named incorrectly in some test config files. ( #340 by )","title":"Bug fixes"},{"location":"governance.html","text":"Governance \u00b6 We follow the same governance model as MNE-Python described here with the exception that the Steering Council and Institutional Partners differ, see below. Steering Council \u00b6 Alex Gramfort Richard Hoechenberger Institutional Partners \u00b6 Institut national de recherche en informatique et en automatique","title":"Governance"},{"location":"governance.html#governance","text":"We follow the same governance model as MNE-Python described here with the exception that the Steering Council and Institutional Partners differ, see below.","title":"Governance"},{"location":"governance.html#steering-council","text":"Alex Gramfort Richard Hoechenberger","title":"Steering Council"},{"location":"governance.html#institutional-partners","text":"Institut national de recherche en informatique et en automatique","title":"Institutional Partners"},{"location":"examples/ERP_CORE.html","text":"ERP CORE \u00b6 This example demonstrate how to process 5 participants from the ERP CORE dataset. It shows how to obtain 7 ERP components from a total of 6 experimental tasks: N170 (face perception) MMN (passive auditory oddball) N2pc (visual search) N400 (word pair judgment) P3b (active visual oddball) LRP and ERN (flankers task) Dataset information \u00b6 Authors: Emily S. Kappenman, Jaclyn L. Farrens, Wendy Zhang, Andrew X. Stewart, and Steven J. Luck License: CC-BY-4.0 URL: https://erpinfo.org/erp-core Citation: Kappenman, E., Farrens, J., Zhang, W., Stewart, A. X., & Luck, S. J. (2021). ERP CORE: An open resource for human event-related potential research. NeuroImage 225: 117465. https://doi.org/10.1016/j.neuroimage.2020.117465 Demonstrated features \u00b6 Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u2705 Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Generated output \u00b6 Summary reports sub-015_ses-ERN_task-ERN_report.html sub-015_ses-LRP_task-LRP_report.html sub-015_ses-MMN_task-MMN_report.html sub-015_ses-N170_task-N170_report.html sub-015_ses-N2pc_task-N2pc_report.html sub-015_ses-N400_task-N400_report.html sub-015_ses-P3_task-P3_report.html sub-016_ses-ERN_task-ERN_report.html sub-016_ses-LRP_task-LRP_report.html sub-016_ses-MMN_task-MMN_report.html sub-016_ses-N170_task-N170_report.html sub-016_ses-N2pc_task-N2pc_report.html sub-016_ses-N400_task-N400_report.html sub-016_ses-P3_task-P3_report.html sub-017_ses-ERN_task-ERN_report.html sub-017_ses-LRP_task-LRP_report.html sub-017_ses-MMN_task-MMN_report.html sub-017_ses-N170_task-N170_report.html sub-017_ses-N2pc_task-N2pc_report.html sub-017_ses-N400_task-N400_report.html sub-017_ses-P3_task-P3_report.html sub-018_ses-ERN_task-ERN_report.html sub-018_ses-LRP_task-LRP_report.html sub-018_ses-MMN_task-MMN_report.html sub-018_ses-N170_task-N170_report.html sub-018_ses-N2pc_task-N2pc_report.html sub-018_ses-N400_task-N400_report.html sub-018_ses-P3_task-P3_report.html sub-019_ses-ERN_task-ERN_report.html sub-019_ses-LRP_task-LRP_report.html sub-019_ses-MMN_task-MMN_report.html sub-019_ses-N170_task-N170_report.html sub-019_ses-N2pc_task-N2pc_report.html sub-019_ses-N400_task-N400_report.html sub-019_ses-P3_task-P3_report.html sub-average_ses-ERN_task-ERN_report.html sub-average_ses-LRP_task-LRP_report.html sub-average_ses-MMN_task-MMN_report.html sub-average_ses-N170_task-N170_report.html sub-average_ses-N2pc_task-N2pc_report.html sub-average_ses-N400_task-N400_report.html sub-average_ses-P3_task-P3_report.html Data cleaning sub-015_ses-ERN_task-ERN_proc-ica+components_report.html sub-015_ses-ERN_task-ERN_proc-ica_report.html sub-015_ses-LRP_task-LRP_proc-ica+components_report.html sub-015_ses-LRP_task-LRP_proc-ica_report.html sub-015_ses-MMN_task-MMN_proc-ica+components_report.html sub-015_ses-MMN_task-MMN_proc-ica_report.html sub-015_ses-N170_task-N170_proc-ica+components_report.html sub-015_ses-N170_task-N170_proc-ica_report.html sub-015_ses-N2pc_task-N2pc_proc-ica+components_report.html sub-015_ses-N2pc_task-N2pc_proc-ica_report.html sub-015_ses-N400_task-N400_proc-ica+components_report.html sub-015_ses-N400_task-N400_proc-ica_report.html sub-015_ses-P3_task-P3_proc-ica+components_report.html sub-015_ses-P3_task-P3_proc-ica_report.html sub-016_ses-ERN_task-ERN_proc-ica+components_report.html sub-016_ses-ERN_task-ERN_proc-ica_report.html sub-016_ses-LRP_task-LRP_proc-ica+components_report.html sub-016_ses-LRP_task-LRP_proc-ica_report.html sub-016_ses-MMN_task-MMN_proc-ica+components_report.html sub-016_ses-MMN_task-MMN_proc-ica_report.html sub-016_ses-N170_task-N170_proc-ica+components_report.html sub-016_ses-N170_task-N170_proc-ica_report.html sub-016_ses-N2pc_task-N2pc_proc-ica+components_report.html sub-016_ses-N2pc_task-N2pc_proc-ica_report.html sub-016_ses-N400_task-N400_proc-ica+components_report.html sub-016_ses-N400_task-N400_proc-ica_report.html sub-016_ses-P3_task-P3_proc-ica+components_report.html sub-016_ses-P3_task-P3_proc-ica_report.html sub-017_ses-ERN_task-ERN_proc-ica+components_report.html sub-017_ses-ERN_task-ERN_proc-ica_report.html sub-017_ses-LRP_task-LRP_proc-ica+components_report.html sub-017_ses-LRP_task-LRP_proc-ica_report.html sub-017_ses-MMN_task-MMN_proc-ica+components_report.html sub-017_ses-MMN_task-MMN_proc-ica_report.html sub-017_ses-N170_task-N170_proc-ica+components_report.html sub-017_ses-N170_task-N170_proc-ica_report.html sub-017_ses-N2pc_task-N2pc_proc-ica+components_report.html sub-017_ses-N2pc_task-N2pc_proc-ica_report.html sub-017_ses-N400_task-N400_proc-ica+components_report.html sub-017_ses-N400_task-N400_proc-ica_report.html sub-017_ses-P3_task-P3_proc-ica+components_report.html sub-017_ses-P3_task-P3_proc-ica_report.html sub-018_ses-ERN_task-ERN_proc-ica+components_report.html sub-018_ses-ERN_task-ERN_proc-ica_report.html sub-018_ses-LRP_task-LRP_proc-ica+components_report.html sub-018_ses-LRP_task-LRP_proc-ica_report.html sub-018_ses-MMN_task-MMN_proc-ica+components_report.html sub-018_ses-MMN_task-MMN_proc-ica_report.html sub-018_ses-N170_task-N170_proc-ica+components_report.html sub-018_ses-N170_task-N170_proc-ica_report.html sub-018_ses-N2pc_task-N2pc_proc-ica+components_report.html sub-018_ses-N2pc_task-N2pc_proc-ica_report.html sub-018_ses-N400_task-N400_proc-ica+components_report.html sub-018_ses-N400_task-N400_proc-ica_report.html sub-018_ses-P3_task-P3_proc-ica+components_report.html sub-018_ses-P3_task-P3_proc-ica_report.html sub-019_ses-ERN_task-ERN_proc-ica+components_report.html sub-019_ses-ERN_task-ERN_proc-ica_report.html sub-019_ses-LRP_task-LRP_proc-ica+components_report.html sub-019_ses-LRP_task-LRP_proc-ica_report.html sub-019_ses-MMN_task-MMN_proc-ica+components_report.html sub-019_ses-MMN_task-MMN_proc-ica_report.html sub-019_ses-N170_task-N170_proc-ica+components_report.html sub-019_ses-N170_task-N170_proc-ica_report.html sub-019_ses-N2pc_task-N2pc_proc-ica+components_report.html sub-019_ses-N2pc_task-N2pc_proc-ica_report.html sub-019_ses-N400_task-N400_proc-ica+components_report.html sub-019_ses-N400_task-N400_proc-ica_report.html sub-019_ses-P3_task-P3_proc-ica+components_report.html sub-019_ses-P3_task-P3_proc-ica_report.html Dataset source \u00b6 This dataset was acquired from https://osf.io/3zk6n/download Configuration \u00b6 import os study_name = 'ERP-CORE' bids_root = '~/mne_data/ERP_CORE' task = os . environ . get ( 'MNE_BIDS_STUDY_TASK' ) sessions = [ task ] subjects = [ '015' , '016' , '017' , '018' , '019' ] ch_types = [ 'eeg' ] interactive = False resample_sfreq = 256 eeg_template_montage = 'standard_1005' eeg_bipolar_channels = { 'HEOG' : ( 'HEOG_left' , 'HEOG_right' ), 'VEOG' : ( 'VEOG_lower' , 'FP2' )} drop_channels = [ 'HEOG_left' , 'HEOG_right' , 'VEOG_lower' ] eog_channels = [ 'HEOG' , 'VEOG' ] l_freq = 0.1 h_freq = None decode = True ica_reject = dict ( eeg = 350e-6 , eog = 500e-6 ) reject = dict ( eeg = 150e-6 ) spatial_filter = 'ica' ica_max_iterations = 1000 ica_eog_threshold = 2 run_source_estimation = False on_error = 'abort' on_rename_missing_events = 'warn' N_JOBS = 10 if task == 'N400' : rename_events = { 'response/201' : 'response/correct' , 'response/202' : 'response/error' , 'stimulus/111' : 'stimulus/prime/related' , 'stimulus/112' : 'stimulus/prime/related' , 'stimulus/121' : 'stimulus/prime/unrelated' , 'stimulus/122' : 'stimulus/prime/unrelated' , 'stimulus/211' : 'stimulus/target/related' , 'stimulus/212' : 'stimulus/target/related' , 'stimulus/221' : 'stimulus/target/unrelated' , 'stimulus/222' : 'stimulus/target/unrelated' , } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tim = - 0.2 epochs_tmax = 0.8 epochs_metadata_tmin = 0 epochs_metadata_tmax = 1.5 epochs_metadata_keep_first = [ 'stimulus/target' , 'response' ] baseline = ( None , 0 ) conditions = { 'related' : '`first_stimulus/target` == \"related\" and ' 'first_response == \"correct\"' , 'unrelated' : '`first_stimulus/target` == \"unrelated\" and ' 'first_response == \"correct\"' } contrasts = [( 'unrelated' , 'related' )] elif task == 'ERN' : rename_events = { 'stimulus/11' : 'compatible/left' , 'stimulus/12' : 'compatible/right' , 'stimulus/21' : 'incompatible/left' , 'stimulus/22' : 'incompatible/right' , 'response/111' : 'response/correct' , 'response/112' : 'response/incorrect' , 'response/121' : 'response/correct' , 'response/122' : 'response/incorrect' , 'response/211' : 'response/incorrect' , 'response/212' : 'response/correct' , 'response/221' : 'response/incorrect' , 'response/222' : 'response/correct' , } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.6 epochs_tmax = 0.4 baseline = ( - 0.4 , - 0.2 ) conditions = [ 'response/correct' , 'response/incorrect' ] contrasts = [( 'response/incorrect' , 'response/correct' )] elif task == 'LRP' : rename_events = { 'stimulus/11' : 'compatible/left' , 'stimulus/12' : 'compatible/right' , 'stimulus/21' : 'incompatible/left' , 'stimulus/22' : 'incompatible/right' , 'response/111' : 'response/left/correct' , 'response/112' : 'response/left/incorrect' , 'response/121' : 'response/left/correct' , 'response/122' : 'response/left/incorrect' , 'response/211' : 'response/right/incorrect' , 'response/212' : 'response/right/correct' , 'response/221' : 'response/right/incorrect' , 'response/222' : 'response/right/correct' , } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.8 epochs_tmax = 0.2 baseline = ( None , - 0.6 ) conditions = [ 'response/left' , 'response/right' ] contrasts = [( 'response/right' , 'response/left' )] # contralateral vs ipsi elif task == 'MMN' : rename_events = { 'stimulus/70' : 'stimulus/deviant' , 'stimulus/80' : 'stimulus/standard' } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.2 epochs_tmax = 0.8 baseline = ( None , 0 ) conditions = [ 'stimulus/standard' , 'stimulus/deviant' ] contrasts = [( 'stimulus/deviant' , 'stimulus/standard' )] elif task == 'N2pc' : rename_events = { 'response/201' : 'response/correct' , 'response/202' : 'response/error' , 'stimulus/111' : 'stimulus/blue/left' , 'stimulus/112' : 'stimulus/blue/left' , 'stimulus/121' : 'stimulus/blue/right' , 'stimulus/122' : 'stimulus/blue/right' , 'stimulus/211' : 'stimulus/pink/left' , 'stimulus/212' : 'stimulus/pink/left' , 'stimulus/221' : 'stimulus/pink/right' , 'stimulus/222' : 'stimulus/pink/right' } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.2 epochs_tmax = 0.8 baseline = ( None , 0 ) conditions = [ 'stimulus/right' , 'stimulus/left' ] contrasts = [( 'stimulus/right' , 'stimulus/left' )] # Contralteral vs ipsi elif task == 'N170' : rename_events = { 'response/201' : 'response/correct' , 'response/202' : 'response/error' } eeg_reference = 'average' ica_n_components = 30 - 1 for i in range ( 1 , 180 + 1 ): orig_name = f 'stimulus/ { i } ' if 1 <= i <= 40 : new_name = f 'stimulus/face/normal' elif 41 <= i <= 80 : new_name = f 'stimulus/car/normal' elif 101 <= i <= 140 : new_name = f 'stimulus/face/scrambled' elif 141 <= i <= 180 : new_name = f 'stimulus/car/scrambled' else : continue rename_events [ orig_name ] = new_name epochs_tmin = - 0.2 epochs_tmax = 0.8 baseline = ( None , 0 ) conditions = [ 'stimulus/face/normal' , 'stimulus/car/normal' ] contrasts = [( 'stimulus/face/normal' , 'stimulus/car/normal' )] elif task == 'P3' : rename_events = { 'response/201' : 'response/correct' , 'response/202' : 'response/incorrect' , 'stimulus/11' : 'stimulus/target/11' , 'stimulus/22' : 'stimulus/target/22' , 'stimulus/33' : 'stimulus/target/33' , 'stimulus/44' : 'stimulus/target/44' , 'stimulus/55' : 'stimulus/target/55' , 'stimulus/21' : 'stimulus/non-target/21' , 'stimulus/31' : 'stimulus/non-target/31' , 'stimulus/41' : 'stimulus/non-target/41' , 'stimulus/51' : 'stimulus/non-target/51' , 'stimulus/12' : 'stimulus/non-target/12' , 'stimulus/32' : 'stimulus/non-target/32' , 'stimulus/42' : 'stimulus/non-target/42' , 'stimulus/52' : 'stimulus/non-target/52' , 'stimulus/13' : 'stimulus/non-target/13' , 'stimulus/23' : 'stimulus/non-target/23' , 'stimulus/43' : 'stimulus/non-target/43' , 'stimulus/53' : 'stimulus/non-target/53' , 'stimulus/14' : 'stimulus/non-target/14' , 'stimulus/24' : 'stimulus/non-target/24' , 'stimulus/34' : 'stimulus/non-target/34' , 'stimulus/54' : 'stimulus/non-target/54' , 'stimulus/15' : 'stimulus/non-target/15' , 'stimulus/25' : 'stimulus/non-target/25' , 'stimulus/35' : 'stimulus/non-target/35' , 'stimulus/45' : 'stimulus/non-target/45' } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.2 epochs_tmax = 0.8 baseline = ( None , 0 ) conditions = [ 'stimulus/target' , 'stimulus/non-target' ] contrasts = [( 'stimulus/target' , 'stimulus/non-target' )] else : raise RuntimeError ( f 'Task { task } not currently supported' )","title":"ERP CORE"},{"location":"examples/ERP_CORE.html#erp-core","text":"This example demonstrate how to process 5 participants from the ERP CORE dataset. It shows how to obtain 7 ERP components from a total of 6 experimental tasks: N170 (face perception) MMN (passive auditory oddball) N2pc (visual search) N400 (word pair judgment) P3b (active visual oddball) LRP and ERN (flankers task)","title":"ERP CORE"},{"location":"examples/ERP_CORE.html#dataset-information","text":"Authors: Emily S. Kappenman, Jaclyn L. Farrens, Wendy Zhang, Andrew X. Stewart, and Steven J. Luck License: CC-BY-4.0 URL: https://erpinfo.org/erp-core Citation: Kappenman, E., Farrens, J., Zhang, W., Stewart, A. X., & Luck, S. J. (2021). ERP CORE: An open resource for human event-related potential research. NeuroImage 225: 117465. https://doi.org/10.1016/j.neuroimage.2020.117465","title":"Dataset information"},{"location":"examples/ERP_CORE.html#demonstrated-features","text":"Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u2705 Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c","title":"Demonstrated features"},{"location":"examples/ERP_CORE.html#generated-output","text":"Summary reports sub-015_ses-ERN_task-ERN_report.html sub-015_ses-LRP_task-LRP_report.html sub-015_ses-MMN_task-MMN_report.html sub-015_ses-N170_task-N170_report.html sub-015_ses-N2pc_task-N2pc_report.html sub-015_ses-N400_task-N400_report.html sub-015_ses-P3_task-P3_report.html sub-016_ses-ERN_task-ERN_report.html sub-016_ses-LRP_task-LRP_report.html sub-016_ses-MMN_task-MMN_report.html sub-016_ses-N170_task-N170_report.html sub-016_ses-N2pc_task-N2pc_report.html sub-016_ses-N400_task-N400_report.html sub-016_ses-P3_task-P3_report.html sub-017_ses-ERN_task-ERN_report.html sub-017_ses-LRP_task-LRP_report.html sub-017_ses-MMN_task-MMN_report.html sub-017_ses-N170_task-N170_report.html sub-017_ses-N2pc_task-N2pc_report.html sub-017_ses-N400_task-N400_report.html sub-017_ses-P3_task-P3_report.html sub-018_ses-ERN_task-ERN_report.html sub-018_ses-LRP_task-LRP_report.html sub-018_ses-MMN_task-MMN_report.html sub-018_ses-N170_task-N170_report.html sub-018_ses-N2pc_task-N2pc_report.html sub-018_ses-N400_task-N400_report.html sub-018_ses-P3_task-P3_report.html sub-019_ses-ERN_task-ERN_report.html sub-019_ses-LRP_task-LRP_report.html sub-019_ses-MMN_task-MMN_report.html sub-019_ses-N170_task-N170_report.html sub-019_ses-N2pc_task-N2pc_report.html sub-019_ses-N400_task-N400_report.html sub-019_ses-P3_task-P3_report.html sub-average_ses-ERN_task-ERN_report.html sub-average_ses-LRP_task-LRP_report.html sub-average_ses-MMN_task-MMN_report.html sub-average_ses-N170_task-N170_report.html sub-average_ses-N2pc_task-N2pc_report.html sub-average_ses-N400_task-N400_report.html sub-average_ses-P3_task-P3_report.html Data cleaning sub-015_ses-ERN_task-ERN_proc-ica+components_report.html sub-015_ses-ERN_task-ERN_proc-ica_report.html sub-015_ses-LRP_task-LRP_proc-ica+components_report.html sub-015_ses-LRP_task-LRP_proc-ica_report.html sub-015_ses-MMN_task-MMN_proc-ica+components_report.html sub-015_ses-MMN_task-MMN_proc-ica_report.html sub-015_ses-N170_task-N170_proc-ica+components_report.html sub-015_ses-N170_task-N170_proc-ica_report.html sub-015_ses-N2pc_task-N2pc_proc-ica+components_report.html sub-015_ses-N2pc_task-N2pc_proc-ica_report.html sub-015_ses-N400_task-N400_proc-ica+components_report.html sub-015_ses-N400_task-N400_proc-ica_report.html sub-015_ses-P3_task-P3_proc-ica+components_report.html sub-015_ses-P3_task-P3_proc-ica_report.html sub-016_ses-ERN_task-ERN_proc-ica+components_report.html sub-016_ses-ERN_task-ERN_proc-ica_report.html sub-016_ses-LRP_task-LRP_proc-ica+components_report.html sub-016_ses-LRP_task-LRP_proc-ica_report.html sub-016_ses-MMN_task-MMN_proc-ica+components_report.html sub-016_ses-MMN_task-MMN_proc-ica_report.html sub-016_ses-N170_task-N170_proc-ica+components_report.html sub-016_ses-N170_task-N170_proc-ica_report.html sub-016_ses-N2pc_task-N2pc_proc-ica+components_report.html sub-016_ses-N2pc_task-N2pc_proc-ica_report.html sub-016_ses-N400_task-N400_proc-ica+components_report.html sub-016_ses-N400_task-N400_proc-ica_report.html sub-016_ses-P3_task-P3_proc-ica+components_report.html sub-016_ses-P3_task-P3_proc-ica_report.html sub-017_ses-ERN_task-ERN_proc-ica+components_report.html sub-017_ses-ERN_task-ERN_proc-ica_report.html sub-017_ses-LRP_task-LRP_proc-ica+components_report.html sub-017_ses-LRP_task-LRP_proc-ica_report.html sub-017_ses-MMN_task-MMN_proc-ica+components_report.html sub-017_ses-MMN_task-MMN_proc-ica_report.html sub-017_ses-N170_task-N170_proc-ica+components_report.html sub-017_ses-N170_task-N170_proc-ica_report.html sub-017_ses-N2pc_task-N2pc_proc-ica+components_report.html sub-017_ses-N2pc_task-N2pc_proc-ica_report.html sub-017_ses-N400_task-N400_proc-ica+components_report.html sub-017_ses-N400_task-N400_proc-ica_report.html sub-017_ses-P3_task-P3_proc-ica+components_report.html sub-017_ses-P3_task-P3_proc-ica_report.html sub-018_ses-ERN_task-ERN_proc-ica+components_report.html sub-018_ses-ERN_task-ERN_proc-ica_report.html sub-018_ses-LRP_task-LRP_proc-ica+components_report.html sub-018_ses-LRP_task-LRP_proc-ica_report.html sub-018_ses-MMN_task-MMN_proc-ica+components_report.html sub-018_ses-MMN_task-MMN_proc-ica_report.html sub-018_ses-N170_task-N170_proc-ica+components_report.html sub-018_ses-N170_task-N170_proc-ica_report.html sub-018_ses-N2pc_task-N2pc_proc-ica+components_report.html sub-018_ses-N2pc_task-N2pc_proc-ica_report.html sub-018_ses-N400_task-N400_proc-ica+components_report.html sub-018_ses-N400_task-N400_proc-ica_report.html sub-018_ses-P3_task-P3_proc-ica+components_report.html sub-018_ses-P3_task-P3_proc-ica_report.html sub-019_ses-ERN_task-ERN_proc-ica+components_report.html sub-019_ses-ERN_task-ERN_proc-ica_report.html sub-019_ses-LRP_task-LRP_proc-ica+components_report.html sub-019_ses-LRP_task-LRP_proc-ica_report.html sub-019_ses-MMN_task-MMN_proc-ica+components_report.html sub-019_ses-MMN_task-MMN_proc-ica_report.html sub-019_ses-N170_task-N170_proc-ica+components_report.html sub-019_ses-N170_task-N170_proc-ica_report.html sub-019_ses-N2pc_task-N2pc_proc-ica+components_report.html sub-019_ses-N2pc_task-N2pc_proc-ica_report.html sub-019_ses-N400_task-N400_proc-ica+components_report.html sub-019_ses-N400_task-N400_proc-ica_report.html sub-019_ses-P3_task-P3_proc-ica+components_report.html sub-019_ses-P3_task-P3_proc-ica_report.html","title":"Generated output"},{"location":"examples/ERP_CORE.html#dataset-source","text":"This dataset was acquired from https://osf.io/3zk6n/download","title":"Dataset source"},{"location":"examples/ERP_CORE.html#configuration","text":"import os study_name = 'ERP-CORE' bids_root = '~/mne_data/ERP_CORE' task = os . environ . get ( 'MNE_BIDS_STUDY_TASK' ) sessions = [ task ] subjects = [ '015' , '016' , '017' , '018' , '019' ] ch_types = [ 'eeg' ] interactive = False resample_sfreq = 256 eeg_template_montage = 'standard_1005' eeg_bipolar_channels = { 'HEOG' : ( 'HEOG_left' , 'HEOG_right' ), 'VEOG' : ( 'VEOG_lower' , 'FP2' )} drop_channels = [ 'HEOG_left' , 'HEOG_right' , 'VEOG_lower' ] eog_channels = [ 'HEOG' , 'VEOG' ] l_freq = 0.1 h_freq = None decode = True ica_reject = dict ( eeg = 350e-6 , eog = 500e-6 ) reject = dict ( eeg = 150e-6 ) spatial_filter = 'ica' ica_max_iterations = 1000 ica_eog_threshold = 2 run_source_estimation = False on_error = 'abort' on_rename_missing_events = 'warn' N_JOBS = 10 if task == 'N400' : rename_events = { 'response/201' : 'response/correct' , 'response/202' : 'response/error' , 'stimulus/111' : 'stimulus/prime/related' , 'stimulus/112' : 'stimulus/prime/related' , 'stimulus/121' : 'stimulus/prime/unrelated' , 'stimulus/122' : 'stimulus/prime/unrelated' , 'stimulus/211' : 'stimulus/target/related' , 'stimulus/212' : 'stimulus/target/related' , 'stimulus/221' : 'stimulus/target/unrelated' , 'stimulus/222' : 'stimulus/target/unrelated' , } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tim = - 0.2 epochs_tmax = 0.8 epochs_metadata_tmin = 0 epochs_metadata_tmax = 1.5 epochs_metadata_keep_first = [ 'stimulus/target' , 'response' ] baseline = ( None , 0 ) conditions = { 'related' : '`first_stimulus/target` == \"related\" and ' 'first_response == \"correct\"' , 'unrelated' : '`first_stimulus/target` == \"unrelated\" and ' 'first_response == \"correct\"' } contrasts = [( 'unrelated' , 'related' )] elif task == 'ERN' : rename_events = { 'stimulus/11' : 'compatible/left' , 'stimulus/12' : 'compatible/right' , 'stimulus/21' : 'incompatible/left' , 'stimulus/22' : 'incompatible/right' , 'response/111' : 'response/correct' , 'response/112' : 'response/incorrect' , 'response/121' : 'response/correct' , 'response/122' : 'response/incorrect' , 'response/211' : 'response/incorrect' , 'response/212' : 'response/correct' , 'response/221' : 'response/incorrect' , 'response/222' : 'response/correct' , } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.6 epochs_tmax = 0.4 baseline = ( - 0.4 , - 0.2 ) conditions = [ 'response/correct' , 'response/incorrect' ] contrasts = [( 'response/incorrect' , 'response/correct' )] elif task == 'LRP' : rename_events = { 'stimulus/11' : 'compatible/left' , 'stimulus/12' : 'compatible/right' , 'stimulus/21' : 'incompatible/left' , 'stimulus/22' : 'incompatible/right' , 'response/111' : 'response/left/correct' , 'response/112' : 'response/left/incorrect' , 'response/121' : 'response/left/correct' , 'response/122' : 'response/left/incorrect' , 'response/211' : 'response/right/incorrect' , 'response/212' : 'response/right/correct' , 'response/221' : 'response/right/incorrect' , 'response/222' : 'response/right/correct' , } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.8 epochs_tmax = 0.2 baseline = ( None , - 0.6 ) conditions = [ 'response/left' , 'response/right' ] contrasts = [( 'response/right' , 'response/left' )] # contralateral vs ipsi elif task == 'MMN' : rename_events = { 'stimulus/70' : 'stimulus/deviant' , 'stimulus/80' : 'stimulus/standard' } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.2 epochs_tmax = 0.8 baseline = ( None , 0 ) conditions = [ 'stimulus/standard' , 'stimulus/deviant' ] contrasts = [( 'stimulus/deviant' , 'stimulus/standard' )] elif task == 'N2pc' : rename_events = { 'response/201' : 'response/correct' , 'response/202' : 'response/error' , 'stimulus/111' : 'stimulus/blue/left' , 'stimulus/112' : 'stimulus/blue/left' , 'stimulus/121' : 'stimulus/blue/right' , 'stimulus/122' : 'stimulus/blue/right' , 'stimulus/211' : 'stimulus/pink/left' , 'stimulus/212' : 'stimulus/pink/left' , 'stimulus/221' : 'stimulus/pink/right' , 'stimulus/222' : 'stimulus/pink/right' } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.2 epochs_tmax = 0.8 baseline = ( None , 0 ) conditions = [ 'stimulus/right' , 'stimulus/left' ] contrasts = [( 'stimulus/right' , 'stimulus/left' )] # Contralteral vs ipsi elif task == 'N170' : rename_events = { 'response/201' : 'response/correct' , 'response/202' : 'response/error' } eeg_reference = 'average' ica_n_components = 30 - 1 for i in range ( 1 , 180 + 1 ): orig_name = f 'stimulus/ { i } ' if 1 <= i <= 40 : new_name = f 'stimulus/face/normal' elif 41 <= i <= 80 : new_name = f 'stimulus/car/normal' elif 101 <= i <= 140 : new_name = f 'stimulus/face/scrambled' elif 141 <= i <= 180 : new_name = f 'stimulus/car/scrambled' else : continue rename_events [ orig_name ] = new_name epochs_tmin = - 0.2 epochs_tmax = 0.8 baseline = ( None , 0 ) conditions = [ 'stimulus/face/normal' , 'stimulus/car/normal' ] contrasts = [( 'stimulus/face/normal' , 'stimulus/car/normal' )] elif task == 'P3' : rename_events = { 'response/201' : 'response/correct' , 'response/202' : 'response/incorrect' , 'stimulus/11' : 'stimulus/target/11' , 'stimulus/22' : 'stimulus/target/22' , 'stimulus/33' : 'stimulus/target/33' , 'stimulus/44' : 'stimulus/target/44' , 'stimulus/55' : 'stimulus/target/55' , 'stimulus/21' : 'stimulus/non-target/21' , 'stimulus/31' : 'stimulus/non-target/31' , 'stimulus/41' : 'stimulus/non-target/41' , 'stimulus/51' : 'stimulus/non-target/51' , 'stimulus/12' : 'stimulus/non-target/12' , 'stimulus/32' : 'stimulus/non-target/32' , 'stimulus/42' : 'stimulus/non-target/42' , 'stimulus/52' : 'stimulus/non-target/52' , 'stimulus/13' : 'stimulus/non-target/13' , 'stimulus/23' : 'stimulus/non-target/23' , 'stimulus/43' : 'stimulus/non-target/43' , 'stimulus/53' : 'stimulus/non-target/53' , 'stimulus/14' : 'stimulus/non-target/14' , 'stimulus/24' : 'stimulus/non-target/24' , 'stimulus/34' : 'stimulus/non-target/34' , 'stimulus/54' : 'stimulus/non-target/54' , 'stimulus/15' : 'stimulus/non-target/15' , 'stimulus/25' : 'stimulus/non-target/25' , 'stimulus/35' : 'stimulus/non-target/35' , 'stimulus/45' : 'stimulus/non-target/45' } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.2 epochs_tmax = 0.8 baseline = ( None , 0 ) conditions = [ 'stimulus/target' , 'stimulus/non-target' ] contrasts = [( 'stimulus/target' , 'stimulus/non-target' )] else : raise RuntimeError ( f 'Task { task } not currently supported' )","title":"Configuration"},{"location":"examples/ds000117.html","text":"Faces dataset \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u2705 Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Generated output \u00b6 Summary reports sub-01_ses-meg_task-facerecognition_report.html sub-average_ses-meg_task-facerecognition_report.html Dataset source \u00b6 This dataset was acquired from https://openneuro.org/datasets/ds000117 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds000117 \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_coordsystem.json \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_events.tsv \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_meg.fif \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-02_events.tsv \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-02_meg.fif \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_headshape.pos \\ --include = derivatives/meg_derivatives/ct_sparse.fif \\ --include = derivatives/meg_derivatives/sss_cal.dat Configuration \u00b6 study_name = 'ds000117' bids_root = '~/mne_data/ds000117' task = 'facerecognition' ch_types = [ 'meg' ] runs = [ '01' , '02' ] sessions = [ 'meg' ] interactive = False acq = None subjects = [ '01' ] resample_sfreq = 125. crop_runs = ( 0 , 350 ) # Reduce memory usage on CI system find_flat_channels_meg = False find_noisy_channels_meg = False use_maxwell_filter = True mf_cal_fname = bids_root + '/derivatives/meg_derivatives/sss_cal.dat' mf_ctc_fname = bids_root + '/derivatives/meg_derivatives/ct_sparse.fif' reject = { 'grad' : 4000e-13 , 'mag' : 4e-12 } conditions = [ 'Famous' , 'Unfamiliar' , 'Scrambled' ] contrasts = [( 'Famous' , 'Scrambled' ), ( 'Unfamiliar' , 'Scrambled' ), ( 'Famous' , 'Unfamiliar' )] decode = True","title":"Faces dataset"},{"location":"examples/ds000117.html#faces-dataset","text":"","title":"Faces dataset"},{"location":"examples/ds000117.html#demonstrated-features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u2705 Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c","title":"Demonstrated features"},{"location":"examples/ds000117.html#generated-output","text":"Summary reports sub-01_ses-meg_task-facerecognition_report.html sub-average_ses-meg_task-facerecognition_report.html","title":"Generated output"},{"location":"examples/ds000117.html#dataset-source","text":"This dataset was acquired from https://openneuro.org/datasets/ds000117 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds000117 \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_coordsystem.json \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_events.tsv \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_meg.fif \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-02_events.tsv \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-02_meg.fif \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_headshape.pos \\ --include = derivatives/meg_derivatives/ct_sparse.fif \\ --include = derivatives/meg_derivatives/sss_cal.dat","title":"Dataset source"},{"location":"examples/ds000117.html#configuration","text":"study_name = 'ds000117' bids_root = '~/mne_data/ds000117' task = 'facerecognition' ch_types = [ 'meg' ] runs = [ '01' , '02' ] sessions = [ 'meg' ] interactive = False acq = None subjects = [ '01' ] resample_sfreq = 125. crop_runs = ( 0 , 350 ) # Reduce memory usage on CI system find_flat_channels_meg = False find_noisy_channels_meg = False use_maxwell_filter = True mf_cal_fname = bids_root + '/derivatives/meg_derivatives/sss_cal.dat' mf_ctc_fname = bids_root + '/derivatives/meg_derivatives/ct_sparse.fif' reject = { 'grad' : 4000e-13 , 'mag' : 4e-12 } conditions = [ 'Famous' , 'Unfamiliar' , 'Scrambled' ] contrasts = [( 'Famous' , 'Scrambled' ), ( 'Unfamiliar' , 'Scrambled' ), ( 'Famous' , 'Unfamiliar' )] decode = True","title":"Configuration"},{"location":"examples/ds000246.html","text":"Auditory MEG \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Generated output \u00b6 Summary reports sub-0001_task-AEF_report.html sub-average_task-AEF_report.html Dataset source \u00b6 This dataset was acquired from https://openneuro.org/datasets/ds000246 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds000246 \\ --include = sub-0001/meg/sub-0001_task-AEF_run-01_meg.ds \\ --include = sub-0001/meg/sub-0001_task-AEF_run-01_meg.json \\ --include = sub-0001/meg/sub-0001_task-AEF_run-01_channels.tsv Configuration \u00b6 study_name = 'ds000246' bids_root = '~/mne_data/ds000246' deriv_root = '~/mne_data/ds000246/derivatives/mne-bids-pipeline' runs = [ '01' ] l_freq = .3 h_freq = 100. decim = 4 subjects = [ '0001' ] ch_types = [ 'meg' ] reject = dict ( mag = 4e-12 , eog = 250e-6 ) conditions = [ 'standard' , 'deviant' , 'button' ] contrasts = [( 'deviant' , 'standard' )] decode = True on_error = 'debug'","title":"Auditory MEG"},{"location":"examples/ds000246.html#auditory-meg","text":"","title":"Auditory MEG"},{"location":"examples/ds000246.html#demonstrated-features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c","title":"Demonstrated features"},{"location":"examples/ds000246.html#generated-output","text":"Summary reports sub-0001_task-AEF_report.html sub-average_task-AEF_report.html","title":"Generated output"},{"location":"examples/ds000246.html#dataset-source","text":"This dataset was acquired from https://openneuro.org/datasets/ds000246 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds000246 \\ --include = sub-0001/meg/sub-0001_task-AEF_run-01_meg.ds \\ --include = sub-0001/meg/sub-0001_task-AEF_run-01_meg.json \\ --include = sub-0001/meg/sub-0001_task-AEF_run-01_channels.tsv","title":"Dataset source"},{"location":"examples/ds000246.html#configuration","text":"study_name = 'ds000246' bids_root = '~/mne_data/ds000246' deriv_root = '~/mne_data/ds000246/derivatives/mne-bids-pipeline' runs = [ '01' ] l_freq = .3 h_freq = 100. decim = 4 subjects = [ '0001' ] ch_types = [ 'meg' ] reject = dict ( mag = 4e-12 , eog = 250e-6 ) conditions = [ 'standard' , 'deviant' , 'button' ] contrasts = [( 'deviant' , 'standard' )] decode = True on_error = 'debug'","title":"Configuration"},{"location":"examples/ds000248.html","text":"MNE Sample Data \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u2705 Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u2705 Generated output \u00b6 Summary reports sub-01_task-audiovisual_report.html sub-average_task-audiovisual_report.html Dataset source \u00b6 This dataset was acquired from https://openneuro.org/datasets/ds000248 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds000248 \\ --include = sub-01 \\ --include = sub-emptyroom \\ --include = derivatives/freesurfer/subjects \\ --exclude = derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2005s+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/fsaverage/mri/aparc+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2009s+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/fsaverage/xhemi/mri/aparc+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/sub-01/mri/aparc+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/sub-01/mri/aparc.a2009s+aseg.mgz Note that we have to explicitly exclude files due to a problem with OpenNeuro's storage. Configuration \u00b6 study_name = 'ds000248' bids_root = '~/mne_data/ds000248' subjects = [ '01' ] rename_events = { 'Smiley' : 'Emoji' , 'Button' : 'Switch' } conditions = [ 'Auditory' , 'Visual' , 'Auditory/Left' , 'Auditory/Right' ] contrasts = [( 'Visual' , 'Auditory' ), ( 'Auditory/Right' , 'Auditory/Left' )] ch_types = [ 'meg' ] mf_reference_run = '01' find_flat_channels_meg = True find_noisy_channels_meg = True use_maxwell_filter = True process_er = True noise_cov = 'emptyroom' bem_mri_images = 'FLASH' recreate_bem = True def mri_t1_path_generator ( bids_path ): # don't really do any modifications \u2013 just for testing! return bids_path","title":"MNE Sample Data"},{"location":"examples/ds000248.html#mne-sample-data","text":"","title":"MNE Sample Data"},{"location":"examples/ds000248.html#demonstrated-features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u2705 Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u2705","title":"Demonstrated features"},{"location":"examples/ds000248.html#generated-output","text":"Summary reports sub-01_task-audiovisual_report.html sub-average_task-audiovisual_report.html","title":"Generated output"},{"location":"examples/ds000248.html#dataset-source","text":"This dataset was acquired from https://openneuro.org/datasets/ds000248 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds000248 \\ --include = sub-01 \\ --include = sub-emptyroom \\ --include = derivatives/freesurfer/subjects \\ --exclude = derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2005s+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/fsaverage/mri/aparc+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2009s+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/fsaverage/xhemi/mri/aparc+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/sub-01/mri/aparc+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/sub-01/mri/aparc.a2009s+aseg.mgz Note that we have to explicitly exclude files due to a problem with OpenNeuro's storage.","title":"Dataset source"},{"location":"examples/ds000248.html#configuration","text":"study_name = 'ds000248' bids_root = '~/mne_data/ds000248' subjects = [ '01' ] rename_events = { 'Smiley' : 'Emoji' , 'Button' : 'Switch' } conditions = [ 'Auditory' , 'Visual' , 'Auditory/Left' , 'Auditory/Right' ] contrasts = [( 'Visual' , 'Auditory' ), ( 'Auditory/Right' , 'Auditory/Left' )] ch_types = [ 'meg' ] mf_reference_run = '01' find_flat_channels_meg = True find_noisy_channels_meg = True use_maxwell_filter = True process_er = True noise_cov = 'emptyroom' bem_mri_images = 'FLASH' recreate_bem = True def mri_t1_path_generator ( bids_path ): # don't really do any modifications \u2013 just for testing! return bids_path","title":"Configuration"},{"location":"examples/ds000248_ica.html","text":"MNE Sample Data: ICA \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u2705 Evoked contrasts \u274c Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Generated output \u00b6 Summary reports sub-01_task-audiovisual_report.html sub-average_task-audiovisual_report.html Data cleaning sub-01_task-audiovisual_proc-ica+components_report.html sub-01_task-audiovisual_proc-ica_report.html Dataset source \u00b6 This dataset was acquired from https://openneuro.org/datasets/ds000248 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds000248 \\ --include = sub-01 Configuration \u00b6 study_name = 'MNE \"sample\" dataset' bids_root = '~/mne_data/ds000248_ica' ch_types = [ 'meg' ] data_type = 'meg' subjects = [ '01' ] task = 'audiovisual' l_freq = 0.3 h_freq = 40.0 conditions = [ 'Auditory/Left' , 'Auditory/Right' , 'Visual/Left' , 'Visual/Right' ] epochs_tmin = - 0.2 epochs_tmax = 0.5 baseline = ( None , 0 ) reject = dict ( mag = 3000e-15 , grad = 3000e-13 ) spatial_filter = 'ica' ica_algorithm = 'extended_infomax' ica_l_freq = 1.0 ica_n_components = 0.8 ica_max_iterations = 500 interactive = False","title":"MNE Sample Data: ICA"},{"location":"examples/ds000248_ica.html#mne-sample-data-ica","text":"","title":"MNE Sample Data: ICA"},{"location":"examples/ds000248_ica.html#demonstrated-features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u2705 Evoked contrasts \u274c Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c","title":"Demonstrated features"},{"location":"examples/ds000248_ica.html#generated-output","text":"Summary reports sub-01_task-audiovisual_report.html sub-average_task-audiovisual_report.html Data cleaning sub-01_task-audiovisual_proc-ica+components_report.html sub-01_task-audiovisual_proc-ica_report.html","title":"Generated output"},{"location":"examples/ds000248_ica.html#dataset-source","text":"This dataset was acquired from https://openneuro.org/datasets/ds000248 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds000248 \\ --include = sub-01","title":"Dataset source"},{"location":"examples/ds000248_ica.html#configuration","text":"study_name = 'MNE \"sample\" dataset' bids_root = '~/mne_data/ds000248_ica' ch_types = [ 'meg' ] data_type = 'meg' subjects = [ '01' ] task = 'audiovisual' l_freq = 0.3 h_freq = 40.0 conditions = [ 'Auditory/Left' , 'Auditory/Right' , 'Visual/Left' , 'Visual/Right' ] epochs_tmin = - 0.2 epochs_tmax = 0.5 baseline = ( None , 0 ) reject = dict ( mag = 3000e-15 , grad = 3000e-13 ) spatial_filter = 'ica' ica_algorithm = 'extended_infomax' ica_l_freq = 1.0 ica_n_components = 0.8 ica_max_iterations = 500 interactive = False","title":"Configuration"},{"location":"examples/ds001810.html","text":"tDCS EEG \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Generated output \u00b6 Summary reports sub-01_ses-anodalpre_task-attentionalblink_report.html sub-02_ses-anodalpre_task-attentionalblink_report.html sub-03_ses-anodalpre_task-attentionalblink_report.html sub-04_ses-anodalpre_task-attentionalblink_report.html sub-05_ses-anodalpre_task-attentionalblink_report.html sub-average_ses-anodalpre_task-attentionalblink_report.html Dataset source \u00b6 This dataset was acquired from https://openneuro.org/datasets/ds001810 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds001810 \\ --include = sub-01/ses-anodalpre \\ --include = sub-02/ses-anodalpre \\ --include = sub-03/ses-anodalpre \\ --include = sub-04/ses-anodalpre \\ --include = sub-05/ses-anodalpre Configuration \u00b6 study_name = 'ds001810' bids_root = '~/mne_data/ds001810' task = 'attentionalblink' interactive = False ch_types = [ 'eeg' ] eeg_template_montage = 'biosemi64' reject = dict ( eeg = 100e-6 ) baseline = ( None , 0 ) conditions = [ '61450' , '61511' ] contrasts = [( '61450' , '61511' )] decode = True l_freq = 0.3 subjects = [ '01' , '02' , '03' , '04' , '05' ] sessions = [ 'anodalpre' ] interpolate_bads_grand_average = False","title":"tDCS EEG"},{"location":"examples/ds001810.html#tdcs-eeg","text":"","title":"tDCS EEG"},{"location":"examples/ds001810.html#demonstrated-features","text":"Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c","title":"Demonstrated features"},{"location":"examples/ds001810.html#generated-output","text":"Summary reports sub-01_ses-anodalpre_task-attentionalblink_report.html sub-02_ses-anodalpre_task-attentionalblink_report.html sub-03_ses-anodalpre_task-attentionalblink_report.html sub-04_ses-anodalpre_task-attentionalblink_report.html sub-05_ses-anodalpre_task-attentionalblink_report.html sub-average_ses-anodalpre_task-attentionalblink_report.html","title":"Generated output"},{"location":"examples/ds001810.html#dataset-source","text":"This dataset was acquired from https://openneuro.org/datasets/ds001810 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds001810 \\ --include = sub-01/ses-anodalpre \\ --include = sub-02/ses-anodalpre \\ --include = sub-03/ses-anodalpre \\ --include = sub-04/ses-anodalpre \\ --include = sub-05/ses-anodalpre","title":"Dataset source"},{"location":"examples/ds001810.html#configuration","text":"study_name = 'ds001810' bids_root = '~/mne_data/ds001810' task = 'attentionalblink' interactive = False ch_types = [ 'eeg' ] eeg_template_montage = 'biosemi64' reject = dict ( eeg = 100e-6 ) baseline = ( None , 0 ) conditions = [ '61450' , '61511' ] contrasts = [( '61450' , '61511' )] decode = True l_freq = 0.3 subjects = [ '01' , '02' , '03' , '04' , '05' ] sessions = [ 'anodalpre' ] interpolate_bads_grand_average = False","title":"Configuration"},{"location":"examples/ds003104.html","text":"Somato \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u274c Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Generated output \u00b6 Summary reports sub-01_task-somato_report.html sub-average_task-somato_report.html Dataset source \u00b6 This dataset was acquired from https://openneuro.org/datasets/ds003104 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds003104 \\ --include = sub-01 \\ --include = derivatives/freesurfer/subjects \\ --exclude = derivatives/freesurfer/subjects/01/mri/aparc+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/01/mri/aparc.DKTatlas+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/01/mri/aparc.a2009s+aseg.mgz Note that we have to explicitly exclude files due to a problem with OpenNeuro's storage. Configuration \u00b6 study_name = 'MNE-somato-data-anonymized' bids_root = '~/mne_data/ds003104' conditions = [ 'somato_event1' ] ch_types = [ 'meg' ]","title":"Somato"},{"location":"examples/ds003104.html#somato","text":"","title":"Somato"},{"location":"examples/ds003104.html#demonstrated-features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u274c Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c","title":"Demonstrated features"},{"location":"examples/ds003104.html#generated-output","text":"Summary reports sub-01_task-somato_report.html sub-average_task-somato_report.html","title":"Generated output"},{"location":"examples/ds003104.html#dataset-source","text":"This dataset was acquired from https://openneuro.org/datasets/ds003104 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds003104 \\ --include = sub-01 \\ --include = derivatives/freesurfer/subjects \\ --exclude = derivatives/freesurfer/subjects/01/mri/aparc+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/01/mri/aparc.DKTatlas+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/01/mri/aparc.a2009s+aseg.mgz Note that we have to explicitly exclude files due to a problem with OpenNeuro's storage.","title":"Dataset source"},{"location":"examples/ds003104.html#configuration","text":"study_name = 'MNE-somato-data-anonymized' bids_root = '~/mne_data/ds003104' conditions = [ 'somato_event1' ] ch_types = [ 'meg' ]","title":"Configuration"},{"location":"examples/ds003392.html","text":"hMT+ Localizer \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u2705 Frequency filter \u2705 SSP \u274c ICA \u2705 Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Generated output \u00b6 Summary reports sub-01_task-localizer_report.html sub-average_task-localizer_report.html Data cleaning sub-01_task-localizer_proc-ica+components_report.html sub-01_task-localizer_proc-ica_report.html Dataset source \u00b6 This dataset was acquired from https://openneuro.org/datasets/ds003392 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds003392 \\ --include = sub-01 \\ --include = sub-emptyroom/ses-19111211 Configuration \u00b6 study_name = 'localizer' bids_root = '~/mne_data/ds003392' subjects = [ '01' ] task = 'localizer' find_flat_channels_meg = True find_noisy_channels_meg = True use_maxwell_filter = True ch_types = [ 'meg' ] l_freq = 1. h_freq = 40. resample_sfreq = 250 # Artifact correction. spatial_filter = 'ica' ica_max_iterations = 500 ica_l_freq = 1. ica_n_components = 0.99 ica_reject_components = 'auto' # Epochs epochs_tmin = - 0.2 epochs_tmax = 1.0 baseline = ( None , 0 ) # Conditions / events to consider when epoching conditions = [ 'coherent' , 'incoherent' ] # Decoding decode = True contrasts = [( 'incoherent' , 'coherent' )] # Noise estimation process_er = True noise_cov = 'emptyroom'","title":"hMT+ Localizer"},{"location":"examples/ds003392.html#hmt-localizer","text":"","title":"hMT+ Localizer"},{"location":"examples/ds003392.html#demonstrated-features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u2705 Frequency filter \u2705 SSP \u274c ICA \u2705 Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c","title":"Demonstrated features"},{"location":"examples/ds003392.html#generated-output","text":"Summary reports sub-01_task-localizer_report.html sub-average_task-localizer_report.html Data cleaning sub-01_task-localizer_proc-ica+components_report.html sub-01_task-localizer_proc-ica_report.html","title":"Generated output"},{"location":"examples/ds003392.html#dataset-source","text":"This dataset was acquired from https://openneuro.org/datasets/ds003392 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds003392 \\ --include = sub-01 \\ --include = sub-emptyroom/ses-19111211","title":"Dataset source"},{"location":"examples/ds003392.html#configuration","text":"study_name = 'localizer' bids_root = '~/mne_data/ds003392' subjects = [ '01' ] task = 'localizer' find_flat_channels_meg = True find_noisy_channels_meg = True use_maxwell_filter = True ch_types = [ 'meg' ] l_freq = 1. h_freq = 40. resample_sfreq = 250 # Artifact correction. spatial_filter = 'ica' ica_max_iterations = 500 ica_l_freq = 1. ica_n_components = 0.99 ica_reject_components = 'auto' # Epochs epochs_tmin = - 0.2 epochs_tmax = 1.0 baseline = ( None , 0 ) # Conditions / events to consider when epoching conditions = [ 'coherent' , 'incoherent' ] # Decoding decode = True contrasts = [( 'incoherent' , 'coherent' )] # Noise estimation process_er = True noise_cov = 'emptyroom'","title":"Configuration"},{"location":"examples/eeg_matchingpennies.html","text":"Matchingpennies EEG experiment \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Generated output \u00b6 Summary reports sub-05_task-matchingpennies_report.html sub-average_task-matchingpennies_report.html Dataset source \u00b6 This dataset was acquired from https://github.com/sappelhoff/eeg_matchingpennies Configuration \u00b6 study_name = 'eeg_matchingpennies' bids_root = '~/mne_data/eeg_matchingpennies' subjects = [ '05' ] task = 'matchingpennies' ch_types = [ 'eeg' ] interactive = False reject = { 'eeg' : 150e-6 } conditions = [ 'left' , 'right' ] contrasts = [( 'right' , 'left' )] decode = True interpolate_bads_grand_average = False","title":"Matchingpennies EEG experiment"},{"location":"examples/eeg_matchingpennies.html#matchingpennies-eeg-experiment","text":"","title":"Matchingpennies EEG experiment"},{"location":"examples/eeg_matchingpennies.html#demonstrated-features","text":"Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c","title":"Demonstrated features"},{"location":"examples/eeg_matchingpennies.html#generated-output","text":"Summary reports sub-05_task-matchingpennies_report.html sub-average_task-matchingpennies_report.html","title":"Generated output"},{"location":"examples/eeg_matchingpennies.html#dataset-source","text":"This dataset was acquired from https://github.com/sappelhoff/eeg_matchingpennies","title":"Dataset source"},{"location":"examples/eeg_matchingpennies.html#configuration","text":"study_name = 'eeg_matchingpennies' bids_root = '~/mne_data/eeg_matchingpennies' subjects = [ '05' ] task = 'matchingpennies' ch_types = [ 'eeg' ] interactive = False reject = { 'eeg' : 150e-6 } conditions = [ 'left' , 'right' ] contrasts = [( 'right' , 'left' )] decode = True interpolate_bads_grand_average = False","title":"Configuration"},{"location":"examples/examples.html","text":"Welcome to our examples gallery.","title":"About examples"},{"location":"features/features.html","text":"What the MNE-BIDS-Pipeline can do \u00b6 preprocessing (filtering, artifact rejection) epoching generation of evoked responses contrasting of experimental conditions time-frequency analysis source estimation All intermediate results are saved to disk for later inspection, and an extensive report is generated. Analyses are conducted on individual (per-subject) as well as group level. Get started","title":"What the pipeline can do"},{"location":"features/features.html#what-the-mne-bids-pipeline-can-do","text":"preprocessing (filtering, artifact rejection) epoching generation of evoked responses contrasting of experimental conditions time-frequency analysis source estimation All intermediate results are saved to disk for later inspection, and an extensive report is generated. Analyses are conducted on individual (per-subject) as well as group level. Get started","title":"What the MNE-BIDS-Pipeline can do"},{"location":"features/steps.html","text":"Processing steps \u00b6 The following table provides a concise summary of each step in the Study Template. You can find the scripts in the scripts directory. Preprocessing \u00b6 Processing step Description preprocessing Run all preprocessing scripts. preprocessing/import_and_maxfilter Import raw data and apply Maxwell filter. preprocessing/frequency_filter Apply low- and high-pass filters. preprocessing/make_epochs Extract epochs. preprocessing/run_ica Run Independant Component Analysis (ICA) for artifact correction. preprocessing/run_ssp Run Signal Subspace Projections (SSP) for artifact correction. These are often also referred to as PCA vectors. preprocessing/apply_ica As an alternative to ICA, you can use SSP projections to correct for eye blink and heart beat artifacts. preprocessing/apply_ssp Apply SSP projections and obtain the cleaned epochs. Sensor-level analysis \u00b6 Processing step Description sensor Run all sensor-level analysis scripts. sensor/make_evoked Extract evoked data for each condition. sensor/sliding_estimator Running a time-by-time decoder with sliding window. sensor/time_frequency Running a time-frequency analysis. sensor/group_average_sensors Make a group average of the time domain data. Source-level analysis \u00b6 Processing step Description source Run all source-level analysis scripts. source/make_forward Compute forward operators. You will need to have computed the coregistration to obtain the -trans.fif files for each subject. source/make_cov Compute noise covariances for each subject. source/make_inverse Compute inverse solution to obtain source estimates. source/group_average Compute source estimates average over subjects. Analysis reports \u00b6 Processing step Description report Run all report-generating scripts (currently only one). report/make_reports.py Compute HTML reports for each subject.","title":"List of processing steps"},{"location":"features/steps.html#processing-steps","text":"The following table provides a concise summary of each step in the Study Template. You can find the scripts in the scripts directory.","title":"Processing steps"},{"location":"features/steps.html#preprocessing","text":"Processing step Description preprocessing Run all preprocessing scripts. preprocessing/import_and_maxfilter Import raw data and apply Maxwell filter. preprocessing/frequency_filter Apply low- and high-pass filters. preprocessing/make_epochs Extract epochs. preprocessing/run_ica Run Independant Component Analysis (ICA) for artifact correction. preprocessing/run_ssp Run Signal Subspace Projections (SSP) for artifact correction. These are often also referred to as PCA vectors. preprocessing/apply_ica As an alternative to ICA, you can use SSP projections to correct for eye blink and heart beat artifacts. preprocessing/apply_ssp Apply SSP projections and obtain the cleaned epochs.","title":"Preprocessing"},{"location":"features/steps.html#sensor-level-analysis","text":"Processing step Description sensor Run all sensor-level analysis scripts. sensor/make_evoked Extract evoked data for each condition. sensor/sliding_estimator Running a time-by-time decoder with sliding window. sensor/time_frequency Running a time-frequency analysis. sensor/group_average_sensors Make a group average of the time domain data.","title":"Sensor-level analysis"},{"location":"features/steps.html#source-level-analysis","text":"Processing step Description source Run all source-level analysis scripts. source/make_forward Compute forward operators. You will need to have computed the coregistration to obtain the -trans.fif files for each subject. source/make_cov Compute noise covariances for each subject. source/make_inverse Compute inverse solution to obtain source estimates. source/group_average Compute source estimates average over subjects.","title":"Source-level analysis"},{"location":"features/steps.html#analysis-reports","text":"Processing step Description report Run all report-generating scripts (currently only one). report/make_reports.py Compute HTML reports for each subject.","title":"Analysis reports"},{"location":"getting_started/basic_usage.html","text":"Prepare your dataset \u00b6 MNE-BIDS-Pipeline only works with BIDS-formatted raw data. To find out more about BIDS and how to convert your data to the BIDS format, please see the documentation of MNE-BIDS . We recommend that faulty channels are marked as \"bad\". Why? While we do run automated bad channel detection in the pipeline, it is considered good practice to flag obviously problematic channels as such in the BIDS dataset. How? MNE-BIDS provides a convenient way to visually inspect raw data and interactively mark problematic channels as bad by using the command mne-bids inspect Please see the MNE-BIDS documentation for more information. the data is anonymized before running the pipeline if you require anonymization, as the pipeline itself does not allow for anonymization. Why? This was a conscious design decision, not a technical limitation per se . If you think this decision should be reconsidered, please get in touch with the developers. How? The write_raw_bids function of MNE-BIDS accepts an anonymize parameter that can be used to anonymize your data by removing subject-identifying information and shifting the measurement date by a given number of days. For example, you could use from mne_bids import write_raw_bids write_raw_bids ( ... , anonymize = dict ( daysback = 1000 )) to shift the recording date 1000 days into the past. By default, information like participant handedness etc. will be removed as well. Please see the documentation of write_raw_bids for more information. Adjust your configuration file \u00b6 The pipeline ships with a default configuration file, config.py . You need to create a copy of that configuration file and adjust all parameters that are relevant to your data processing and analysis. Avoid modifying the scripts You should only need to touch the configuration file. None of the scripts should be edited. Run the pipeline \u00b6 Run the full pipeline To run the full pipeline, execute the following command in your terminal: python run.py --config = /path/to/your/custom_config.py Run only parts of the pipeline Run only the preprocessing steps: python run.py --config = /path/to/your/custom_config.py --steps = preprocessing Run only the sensor-level processing steps: python run.py --config = /path/to/your/custom_config.py --steps = sensor Run only the source-level (inverse solution) processing steps: python run.py --config = /path/to/your/custom_config.py --steps = source Only generate the report: python run.py --config = /path/to/your/custom_config.py --steps = report (Re-)run ICA: python run.py --config = /path/to/your/custom_config.py \\ --steps = preprocessing/ica You can also run multiple steps with one command by separating different steps by a comma. For example, to run preprocessing and sensor-level processing steps using a single command, do: python run.py --config = /path/to/your/custom_config.py \\ --steps = preprocessing,sensor","title":"Basic usage"},{"location":"getting_started/basic_usage.html#prepare-your-dataset","text":"MNE-BIDS-Pipeline only works with BIDS-formatted raw data. To find out more about BIDS and how to convert your data to the BIDS format, please see the documentation of MNE-BIDS . We recommend that faulty channels are marked as \"bad\". Why? While we do run automated bad channel detection in the pipeline, it is considered good practice to flag obviously problematic channels as such in the BIDS dataset. How? MNE-BIDS provides a convenient way to visually inspect raw data and interactively mark problematic channels as bad by using the command mne-bids inspect Please see the MNE-BIDS documentation for more information. the data is anonymized before running the pipeline if you require anonymization, as the pipeline itself does not allow for anonymization. Why? This was a conscious design decision, not a technical limitation per se . If you think this decision should be reconsidered, please get in touch with the developers. How? The write_raw_bids function of MNE-BIDS accepts an anonymize parameter that can be used to anonymize your data by removing subject-identifying information and shifting the measurement date by a given number of days. For example, you could use from mne_bids import write_raw_bids write_raw_bids ( ... , anonymize = dict ( daysback = 1000 )) to shift the recording date 1000 days into the past. By default, information like participant handedness etc. will be removed as well. Please see the documentation of write_raw_bids for more information.","title":"Prepare your dataset"},{"location":"getting_started/basic_usage.html#adjust-your-configuration-file","text":"The pipeline ships with a default configuration file, config.py . You need to create a copy of that configuration file and adjust all parameters that are relevant to your data processing and analysis. Avoid modifying the scripts You should only need to touch the configuration file. None of the scripts should be edited.","title":"Adjust your configuration file"},{"location":"getting_started/basic_usage.html#run-the-pipeline","text":"Run the full pipeline To run the full pipeline, execute the following command in your terminal: python run.py --config = /path/to/your/custom_config.py Run only parts of the pipeline Run only the preprocessing steps: python run.py --config = /path/to/your/custom_config.py --steps = preprocessing Run only the sensor-level processing steps: python run.py --config = /path/to/your/custom_config.py --steps = sensor Run only the source-level (inverse solution) processing steps: python run.py --config = /path/to/your/custom_config.py --steps = source Only generate the report: python run.py --config = /path/to/your/custom_config.py --steps = report (Re-)run ICA: python run.py --config = /path/to/your/custom_config.py \\ --steps = preprocessing/ica You can also run multiple steps with one command by separating different steps by a comma. For example, to run preprocessing and sensor-level processing steps using a single command, do: python run.py --config = /path/to/your/custom_config.py \\ --steps = preprocessing,sensor","title":"Run the pipeline"},{"location":"getting_started/freesurfer.html","text":"To perform inverse modeling, or also called source estimation or source localization, we need to ensure that a couple prerequisities are met. Essentially, starting from a collection of 2-dimensional MRI images of coronal, axial, and saggital slices of a participant's head, we need to construct a 3-dimensional representation of the brain, skull, and scalp. Furthermore, it's highly advantegous to attach labels to different brain areas according to common anatomical atlases, so that we could, for example, restrict subsequent analyses to specific cortical regions, and compare activation in these regions across participants. BIDS raw datasets, however, do not include any of these 3D representations and parcellations. (Note that, however, these derivatives are sometimes distributed along with a datasets inside a derivatives/ folder). Instead, they ship e.g. with T1-weighted images only (and, sometimes, include FLASH images too). Install FreeSurfer \u00b6 Before running the source-analysis parts of the pipeline, you need to create the above-mentioned 3D surfaces and parcellations. This is done using the FreeSurfer tool. FreeSurfer is a free software package that runs on macOS and Linux. To install FreeSurfer 6, follow the official download and installation nstructions . Info The only currently supported FreeSurfer version is 6.0 . Warning FreeSurfer does not natively run on Windows. We are currently working on ways to make it possible to use it on Windows, too. Warning FreeSurfer cannot currently be used on macOS Big Sur (other macOS versions work fine). We are working on a solution. Generate surfaces and brain parcellation \u00b6 MNE-BIDS-Pipeline provides a convenient way to invoke FreeSurfer. After adjusting your configuration file , invoke FreeSurfer via the run.py script in the following way: python run.py freesurfer --config = /path/to/your/custom_config.py This will run the recon-all command to create the required surfaces. Info This process is very computationally expensive, and will usually take several hours to complete. It's a good idea to let this command run over night. Run source-level analyses \u00b6 Now you are ready to run MNE-BIDS-Pipeline, including all parts of inverse modeling. To perform the projection, MNE-Python will first need to detect brain, skull, and skin, so it can then start constructing the actual BEM conductor model. These BEM surfaces can be created based on FLASH MRI (best option) or T1-weighted MRI images (second-best). See the respective configuration options to control BEM surface creation.","title":"Preparations for source-level analyses"},{"location":"getting_started/freesurfer.html#install-freesurfer","text":"Before running the source-analysis parts of the pipeline, you need to create the above-mentioned 3D surfaces and parcellations. This is done using the FreeSurfer tool. FreeSurfer is a free software package that runs on macOS and Linux. To install FreeSurfer 6, follow the official download and installation nstructions . Info The only currently supported FreeSurfer version is 6.0 . Warning FreeSurfer does not natively run on Windows. We are currently working on ways to make it possible to use it on Windows, too. Warning FreeSurfer cannot currently be used on macOS Big Sur (other macOS versions work fine). We are working on a solution.","title":"Install FreeSurfer"},{"location":"getting_started/freesurfer.html#generate-surfaces-and-brain-parcellation","text":"MNE-BIDS-Pipeline provides a convenient way to invoke FreeSurfer. After adjusting your configuration file , invoke FreeSurfer via the run.py script in the following way: python run.py freesurfer --config = /path/to/your/custom_config.py This will run the recon-all command to create the required surfaces. Info This process is very computationally expensive, and will usually take several hours to complete. It's a good idea to let this command run over night.","title":"Generate surfaces and brain parcellation"},{"location":"getting_started/freesurfer.html#run-source-level-analyses","text":"Now you are ready to run MNE-BIDS-Pipeline, including all parts of inverse modeling. To perform the projection, MNE-Python will first need to detect brain, skull, and skin, so it can then start constructing the actual BEM conductor model. These BEM surfaces can be created based on FLASH MRI (best option) or T1-weighted MRI images (second-best). See the respective configuration options to control BEM surface creation.","title":"Run source-level analyses"},{"location":"getting_started/install.html","text":"Install MNE-Python \u00b6 First, you need to make sure you have MNE-Python installed and working on your system. See the installation instructions . Install additional dependencies \u00b6 You will also need to install the a number of additional dependencies that are required to run the pipeline. Install for Python 3.8 and newer Run in your terminal: pip install mne-bids coloredlogs tqdm pandas scikit-learn json_tricks fire Install for older Python versions Run in your terminal: pip install mne-bids coloredlogs tqdm pandas json_tricks scikit-learn fire typing_extensions Detailed list of dependencies mne-bids to operate on BIDS data coloredlogs for nicer logging output tqdm for progress bars pandas for table creation json_tricks for handling of some analysis output scikit-learn for decoding fire for the command line interface typing_extensions if you're using a Python version older than 3.8 Download MNE-BIDS-Pipeline \u00b6 TODO","title":"Installation"},{"location":"getting_started/install.html#install-mne-python","text":"First, you need to make sure you have MNE-Python installed and working on your system. See the installation instructions .","title":"Install MNE-Python"},{"location":"getting_started/install.html#install-additional-dependencies","text":"You will also need to install the a number of additional dependencies that are required to run the pipeline. Install for Python 3.8 and newer Run in your terminal: pip install mne-bids coloredlogs tqdm pandas scikit-learn json_tricks fire Install for older Python versions Run in your terminal: pip install mne-bids coloredlogs tqdm pandas json_tricks scikit-learn fire typing_extensions Detailed list of dependencies mne-bids to operate on BIDS data coloredlogs for nicer logging output tqdm for progress bars pandas for table creation json_tricks for handling of some analysis output scikit-learn for decoding fire for the command line interface typing_extensions if you're using a Python version older than 3.8","title":"Install additional dependencies"},{"location":"getting_started/install.html#download-mne-bids-pipeline","text":"TODO","title":"Download MNE-BIDS-Pipeline"},{"location":"settings/general.html","text":"study_name : str \u00b6 Specify the name of your study. It will be used to populate filenames for saving the analysis results. Example study_name = 'my-study' bids_root : Union [ str , pathlib . Path ] \u00b6 Specify the BIDS root directory. Pass an empty string or `None to use the value specified in the BIDS_ROOT environment variable instead. Raises an exception if the BIDS root has not been specified. Example bids_root = '/path/to/your/bids_root' # Use this to specify a path here. bids_root = None # Make use of the ``BIDS_ROOT`` environment variable. deriv_root : Union [ str , pathlib . Path ] \u00b6 The root of the derivatives directory in which the pipeline will store the processing results. If None , this will be derivatives/mne-bids-pipeline inside the BIDS root. subjects_dir : Union [ str , pathlib . Path ] \u00b6 Path to the directory that contains the MRI data files and their derivativesfor all subjects. Specifically, the subjects_dir is the $SUBJECTS_DIR used by the Freesurfer software. interactive : bool \u00b6 If True, the scripts will provide some interactive elements, such as figures. If running the scripts from a notebook or Spyder, run %matplotlib qt in the command line to open the figures in a separate window. sessions : Union [ List , Literal [ 'all' ]] \u00b6 The sessions to process. task : str \u00b6 The task to process. runs : Union [ Iterable , Literal [ 'all' ]] \u00b6 The runs to process. crop_runs : Optional [ Tuple [ float , float ]] \u00b6 Crop the raw data of each run to the specified time interval [tmin, tmax] , in seconds. The runs will be cropped before Maxwell or frequency filtering is applied. If None , do not crop the data. acq : Optional [ str ] \u00b6 The BIDS acquisition entity. proc : Optional [ str ] \u00b6 The BIDS processing entity. rec : Optional [ str ] \u00b6 The BIDS recording entity. space : Optional [ str ] \u00b6 The BIDS space entity. subjects : Union [ Iterable [ str ], Literal [ 'all' ]] \u00b6 Subjects to analyze. If 'all' , include all subjects. To only include a subset of subjects, pass a list of their identifiers. Even if you plan on analyzing only a single subject, pass their identifier as a list. Please note that if you intend to EXCLUDE only a few subjects, you should consider setting subjects = 'all' and adding the identifiers of the excluded subjects to exclude_subjects (see next section). Example subjects = 'all' # Include all subjects. subjects = [ '05' ] # Only include subject 05. subjects = [ '01' , '02' ] # Only include subjects 01 and 02. exclude_subjects : Iterable [ str ] \u00b6 Specify subjects to exclude from analysis. The MEG empty-room mock-subject is automatically excluded from regular analysis. Good Practice / Advice Keep track of the criteria leading you to exclude a participant (e.g. too many movements, missing blocks, aborted experiment, did not understand the instructions, etc, ...) The emptyroom subject will be excluded automatically. process_er : bool \u00b6 Whether to apply the same pre-processing steps to the empty-room data as to the experimental data (up until including frequency filtering). This is required if you wish to use the empty-room recording to estimate noise covariance (via noise_cov='emptyroom' ). The empty-room recording corresponding to the processed experimental data will be retrieved automatically. ch_types : Iterable [ Literal [ 'meg' , 'mag' , 'grad' , 'eeg' ]] \u00b6 The channel types to consider. Info Currently, MEG and EEG data cannot be processed together. Example # Use EEG channels: ch_types = [ 'eeg' ] # Use magnetometer and gradiometer MEG channels: ch_types = [ 'mag' , 'grad' ] # Currently does not work and will raise an error message: ch_types = [ 'meg' , 'eeg' ] data_type : Optional [ Literal [ 'meg' , 'eeg' ]] \u00b6 The BIDS data type. For MEG recordings, this will usually be 'meg'; and for EEG, 'eeg'. However, if your dataset contains simultaneous recordings of MEG and EEG, stored in a single file, you will typically need to set this to 'meg'. If None , we will assume that the data type matches the channel type. Example The dataset contains simultaneous recordings of MEG and EEG, and we only wish to process the EEG data, which is stored inside the MEG files: ch_types = [ 'eeg' ] data_type = 'eeg' The dataset contains simultaneous recordings of MEG and EEG, and we only wish to process the gradiometer data: ch_types = [ 'grad' ] data_type = 'meg' # or data_type = None The dataset contains only EEG data: ch_types = [ 'eeg' ] data_type = 'eeg' # or data_type = None eog_channels : Optional [ Iterable [ str ]] \u00b6 Specify EOG channels to use, or create virtual EOG channels. Allows the specification of custom channel names that shall be used as (virtual) EOG channels. For example, say you recorded EEG without dedicated EOG electrodes, but with some EEG electrodes placed close to the eyes, e.g. Fp1 and Fp2. These channels can be expected to have captured large quantities of ocular activity, and you might want to use them as \"virtual\" EOG channels, while also including them in the EEG analysis. By default, MNE won't know that these channels are suitable for recovering EOG, and hence won't be able to perform tasks like automated blink removal, unless a \"true\" EOG sensor is present in the data as well. Specifying channel names here allows MNE to find the respective EOG signals based on these channels. You can specify one or multiple channel names. Each will be treated as if it were a dedicated EOG channel, without excluding it from any other analyses. If None , only actual EOG channels will be used for EOG recovery. If there are multiple actual EOG channels in your data, and you only specify a subset of them here, only this subset will be used during processing. Example Treat Fp1 as virtual EOG channel: eog_channels = [ 'Fp1' ] Treat Fp1 and Fp2 as virtual EOG channels: eog_channels = [ 'Fp1' , 'Fp2' ] eeg_bipolar_channels : Optional [ Dict [ str , Tuple [ str , str ]]] \u00b6 Combine two channels into a bipolar channel, whose signal is the difference between the two combined channels, and add it to the data. A typical use case is the combination of two EOG channels \u2013 for example, a left and a right horizontal EOG \u2013 into a single, bipolar EOG channel. You need to pass a dictionary whose keys are the name of the new bipolar channel you wish to create, and whose values are tuples consisting of two strings: the name of the channel acting as anode and the name of the channel acting as cathode, i.e. {'ch_name': ('anode', 'cathode')} . You can request to construct more than one bipolar channel by specifying multiple key/value pairs. See the examples below. Can also be None if you do not want to create bipolar channels. Note The channels used to create the bipolar channels are not automatically dropped from the data. To drop channels, set drop_channels . Example Combine the existing channels HEOG_left and HEOG_right into a new, bipolar channel, HEOG : eeg_add_bipolar_channels = { 'HEOG' : ( 'HEOG_left' , 'HEOG_right' )} Create two bipolar channels, HEOG and VEOG : eeg_add_bipolar_channels = { 'HEOG' : ( 'HEOG_left' , 'HEOG_right' ), 'VEOG' : ( 'VEOG_lower' , 'VEOG_upper' )} eeg_reference : Union [ Literal [ 'average' ], str , Iterable [ str ]] \u00b6 The EEG reference to use. If average , will use the average reference, i.e. the average across all channels. If a string, must be the name of a single channel. To use multiple channels as reference, set to a list of channel names. Example Use the average reference: eeg_reference = 'average' Use the P9 channel as reference: eeg_reference = 'P9' Use the average of the P9 and P10 channels as reference: eeg_reference = [ 'P9' , 'P10' ] eeg_template_montage : Optional [ str ] \u00b6 In situations where you wish to process EEG data and no individual digitization points (measured channel locations) are available, you can apply a \"template\" montage. This means we will assume the EEG cap was placed either according to an international system like 10/20, or as suggested by the cap manufacturers in their respective manual. Please be aware that the actual cap placement most likely deviated somewhat from the template, and, therefore, source reconstruction may be impaired. If None , do not apply a template montage. If a string, must be the name of a built-in template montage in MNE-Python. You can find an overview of supported template montages at https://mne.tools/stable/generated/mne.channels.make_standard_montage.html Example Do not apply template montage: eeg_template_montage = None Apply 64-channel Biosemi 10/20 template montage: eeg_template_montage = 'biosemi64' drop_channels : Iterable [ str ] \u00b6 Names of channels to remove from the data. This can be useful, for example, if you have added a new bipolar channel via eeg_bipolar_channels and now wish to remove the anode, cathode, or both. Example Exclude channels Fp1 and Cz from processing: drop_channels = [ 'Fp1' , 'Cz] analyze_channels : Union [ Literal [ 'all' ], Iterable [ str ]] \u00b6 The names of the channels to analyze during ERP/ERF and time-frequency analysis steps. For certain paradigms, e.g. EEG ERP research, it is common to contrain sensor-space analysis to only a few specific sensors. If 'all' , do not exclude any channels (except for those selected for removal via the drop_channels setting). The constraint will be applied to all sensor-level analyses after the preprocessing stage, but not to the preprocessing stage itself, nor to the source analysis stage. Example Only use channel Pz for ERP, evoked contrasts, time-by-time decoding, and time-frequency analysis: analyze_channels = [ 'Pz' ]","title":"General settings"},{"location":"settings/general.html#config.study_name","text":"Specify the name of your study. It will be used to populate filenames for saving the analysis results. Example study_name = 'my-study'","title":"study_name"},{"location":"settings/general.html#config.bids_root","text":"Specify the BIDS root directory. Pass an empty string or `None to use the value specified in the BIDS_ROOT environment variable instead. Raises an exception if the BIDS root has not been specified. Example bids_root = '/path/to/your/bids_root' # Use this to specify a path here. bids_root = None # Make use of the ``BIDS_ROOT`` environment variable.","title":"bids_root"},{"location":"settings/general.html#config.deriv_root","text":"The root of the derivatives directory in which the pipeline will store the processing results. If None , this will be derivatives/mne-bids-pipeline inside the BIDS root.","title":"deriv_root"},{"location":"settings/general.html#config.subjects_dir","text":"Path to the directory that contains the MRI data files and their derivativesfor all subjects. Specifically, the subjects_dir is the $SUBJECTS_DIR used by the Freesurfer software.","title":"subjects_dir"},{"location":"settings/general.html#config.interactive","text":"If True, the scripts will provide some interactive elements, such as figures. If running the scripts from a notebook or Spyder, run %matplotlib qt in the command line to open the figures in a separate window.","title":"interactive"},{"location":"settings/general.html#config.sessions","text":"The sessions to process.","title":"sessions"},{"location":"settings/general.html#config.task","text":"The task to process.","title":"task"},{"location":"settings/general.html#config.runs","text":"The runs to process.","title":"runs"},{"location":"settings/general.html#config.crop_runs","text":"Crop the raw data of each run to the specified time interval [tmin, tmax] , in seconds. The runs will be cropped before Maxwell or frequency filtering is applied. If None , do not crop the data.","title":"crop_runs"},{"location":"settings/general.html#config.acq","text":"The BIDS acquisition entity.","title":"acq"},{"location":"settings/general.html#config.proc","text":"The BIDS processing entity.","title":"proc"},{"location":"settings/general.html#config.rec","text":"The BIDS recording entity.","title":"rec"},{"location":"settings/general.html#config.space","text":"The BIDS space entity.","title":"space"},{"location":"settings/general.html#config.subjects","text":"Subjects to analyze. If 'all' , include all subjects. To only include a subset of subjects, pass a list of their identifiers. Even if you plan on analyzing only a single subject, pass their identifier as a list. Please note that if you intend to EXCLUDE only a few subjects, you should consider setting subjects = 'all' and adding the identifiers of the excluded subjects to exclude_subjects (see next section). Example subjects = 'all' # Include all subjects. subjects = [ '05' ] # Only include subject 05. subjects = [ '01' , '02' ] # Only include subjects 01 and 02.","title":"subjects"},{"location":"settings/general.html#config.exclude_subjects","text":"Specify subjects to exclude from analysis. The MEG empty-room mock-subject is automatically excluded from regular analysis. Good Practice / Advice Keep track of the criteria leading you to exclude a participant (e.g. too many movements, missing blocks, aborted experiment, did not understand the instructions, etc, ...) The emptyroom subject will be excluded automatically.","title":"exclude_subjects"},{"location":"settings/general.html#config.process_er","text":"Whether to apply the same pre-processing steps to the empty-room data as to the experimental data (up until including frequency filtering). This is required if you wish to use the empty-room recording to estimate noise covariance (via noise_cov='emptyroom' ). The empty-room recording corresponding to the processed experimental data will be retrieved automatically.","title":"process_er"},{"location":"settings/general.html#config.ch_types","text":"The channel types to consider. Info Currently, MEG and EEG data cannot be processed together. Example # Use EEG channels: ch_types = [ 'eeg' ] # Use magnetometer and gradiometer MEG channels: ch_types = [ 'mag' , 'grad' ] # Currently does not work and will raise an error message: ch_types = [ 'meg' , 'eeg' ]","title":"ch_types"},{"location":"settings/general.html#config.data_type","text":"The BIDS data type. For MEG recordings, this will usually be 'meg'; and for EEG, 'eeg'. However, if your dataset contains simultaneous recordings of MEG and EEG, stored in a single file, you will typically need to set this to 'meg'. If None , we will assume that the data type matches the channel type. Example The dataset contains simultaneous recordings of MEG and EEG, and we only wish to process the EEG data, which is stored inside the MEG files: ch_types = [ 'eeg' ] data_type = 'eeg' The dataset contains simultaneous recordings of MEG and EEG, and we only wish to process the gradiometer data: ch_types = [ 'grad' ] data_type = 'meg' # or data_type = None The dataset contains only EEG data: ch_types = [ 'eeg' ] data_type = 'eeg' # or data_type = None","title":"data_type"},{"location":"settings/general.html#config.eog_channels","text":"Specify EOG channels to use, or create virtual EOG channels. Allows the specification of custom channel names that shall be used as (virtual) EOG channels. For example, say you recorded EEG without dedicated EOG electrodes, but with some EEG electrodes placed close to the eyes, e.g. Fp1 and Fp2. These channels can be expected to have captured large quantities of ocular activity, and you might want to use them as \"virtual\" EOG channels, while also including them in the EEG analysis. By default, MNE won't know that these channels are suitable for recovering EOG, and hence won't be able to perform tasks like automated blink removal, unless a \"true\" EOG sensor is present in the data as well. Specifying channel names here allows MNE to find the respective EOG signals based on these channels. You can specify one or multiple channel names. Each will be treated as if it were a dedicated EOG channel, without excluding it from any other analyses. If None , only actual EOG channels will be used for EOG recovery. If there are multiple actual EOG channels in your data, and you only specify a subset of them here, only this subset will be used during processing. Example Treat Fp1 as virtual EOG channel: eog_channels = [ 'Fp1' ] Treat Fp1 and Fp2 as virtual EOG channels: eog_channels = [ 'Fp1' , 'Fp2' ]","title":"eog_channels"},{"location":"settings/general.html#config.eeg_bipolar_channels","text":"Combine two channels into a bipolar channel, whose signal is the difference between the two combined channels, and add it to the data. A typical use case is the combination of two EOG channels \u2013 for example, a left and a right horizontal EOG \u2013 into a single, bipolar EOG channel. You need to pass a dictionary whose keys are the name of the new bipolar channel you wish to create, and whose values are tuples consisting of two strings: the name of the channel acting as anode and the name of the channel acting as cathode, i.e. {'ch_name': ('anode', 'cathode')} . You can request to construct more than one bipolar channel by specifying multiple key/value pairs. See the examples below. Can also be None if you do not want to create bipolar channels. Note The channels used to create the bipolar channels are not automatically dropped from the data. To drop channels, set drop_channels . Example Combine the existing channels HEOG_left and HEOG_right into a new, bipolar channel, HEOG : eeg_add_bipolar_channels = { 'HEOG' : ( 'HEOG_left' , 'HEOG_right' )} Create two bipolar channels, HEOG and VEOG : eeg_add_bipolar_channels = { 'HEOG' : ( 'HEOG_left' , 'HEOG_right' ), 'VEOG' : ( 'VEOG_lower' , 'VEOG_upper' )}","title":"eeg_bipolar_channels"},{"location":"settings/general.html#config.eeg_reference","text":"The EEG reference to use. If average , will use the average reference, i.e. the average across all channels. If a string, must be the name of a single channel. To use multiple channels as reference, set to a list of channel names. Example Use the average reference: eeg_reference = 'average' Use the P9 channel as reference: eeg_reference = 'P9' Use the average of the P9 and P10 channels as reference: eeg_reference = [ 'P9' , 'P10' ]","title":"eeg_reference"},{"location":"settings/general.html#config.eeg_template_montage","text":"In situations where you wish to process EEG data and no individual digitization points (measured channel locations) are available, you can apply a \"template\" montage. This means we will assume the EEG cap was placed either according to an international system like 10/20, or as suggested by the cap manufacturers in their respective manual. Please be aware that the actual cap placement most likely deviated somewhat from the template, and, therefore, source reconstruction may be impaired. If None , do not apply a template montage. If a string, must be the name of a built-in template montage in MNE-Python. You can find an overview of supported template montages at https://mne.tools/stable/generated/mne.channels.make_standard_montage.html Example Do not apply template montage: eeg_template_montage = None Apply 64-channel Biosemi 10/20 template montage: eeg_template_montage = 'biosemi64'","title":"eeg_template_montage"},{"location":"settings/general.html#config.drop_channels","text":"Names of channels to remove from the data. This can be useful, for example, if you have added a new bipolar channel via eeg_bipolar_channels and now wish to remove the anode, cathode, or both. Example Exclude channels Fp1 and Cz from processing: drop_channels = [ 'Fp1' , 'Cz]","title":"drop_channels"},{"location":"settings/general.html#config.analyze_channels","text":"The names of the channels to analyze during ERP/ERF and time-frequency analysis steps. For certain paradigms, e.g. EEG ERP research, it is common to contrain sensor-space analysis to only a few specific sensors. If 'all' , do not exclude any channels (except for those selected for removal via the drop_channels setting). The constraint will be applied to all sensor-level analyses after the preprocessing stage, but not to the preprocessing stage itself, nor to the source analysis stage. Example Only use channel Pz for ERP, evoked contrasts, time-by-time decoding, and time-frequency analysis: analyze_channels = [ 'Pz' ]","title":"analyze_channels"},{"location":"settings/preprocessing/artifacts.html","text":"Good Practice / Advice Have a look at your raw data and train yourself to detect a blink, a heart beat and an eye movement. You can do a quick average of blink data and check what the amplitude looks like. reject : Optional [ Dict [ str , float ]] \u00b6 Peak-to-peak amplitude limits to mark epochs as bad. This allows you to remove epochs with strong transient artifacts. Note The rejection is performed after SSP or ICA, if any of those methods is used. To reject epochs before fitting ICA, see the ica_reject setting. Pass None to avoid automated epoch rejection based on amplitude. Example reject = { 'grad' : 4000e-13 , 'mag' : 4e-12 , 'eog' : 150e-6 } reject = { 'eeg' : 100e-6 , 'eog' : 250e-6 } reject = None reject_tmin : Optional [ float ] \u00b6 Start of the time window used to reject epochs. If None , the window will start with the first time point. Example reject_tmin = - 0.1 # 100 ms before event onset. reject_tmax : Optional [ float ] \u00b6 End of the time window used to reject epochs. If None , the window will end with the last time point. Example reject_tmax = 0.3 # 300 ms after event onset.","title":"Amplitude-based"},{"location":"settings/preprocessing/artifacts.html#config.reject","text":"Peak-to-peak amplitude limits to mark epochs as bad. This allows you to remove epochs with strong transient artifacts. Note The rejection is performed after SSP or ICA, if any of those methods is used. To reject epochs before fitting ICA, see the ica_reject setting. Pass None to avoid automated epoch rejection based on amplitude. Example reject = { 'grad' : 4000e-13 , 'mag' : 4e-12 , 'eog' : 150e-6 } reject = { 'eeg' : 100e-6 , 'eog' : 250e-6 } reject = None","title":"reject"},{"location":"settings/preprocessing/artifacts.html#config.reject_tmin","text":"Start of the time window used to reject epochs. If None , the window will start with the first time point. Example reject_tmin = - 0.1 # 100 ms before event onset.","title":"reject_tmin"},{"location":"settings/preprocessing/artifacts.html#config.reject_tmax","text":"End of the time window used to reject epochs. If None , the window will end with the last time point. Example reject_tmax = 0.3 # 300 ms after event onset.","title":"reject_tmax"},{"location":"settings/preprocessing/autobads.html","text":"Warning This functionality will soon be removed from the pipeline, and will be integrated into MNE-BIDS. \"Bad\", i.e. flat and overly noisy channels, can be automatically detected using a procedure inspired by the commercial MaxFilter by Elekta. First, a copy of the data is low-pass filtered at 40 Hz. Then, channels with unusually low variability are flagged as \"flat\", while channels with excessively high variability are flagged as \"noisy\". Flat and noisy channels are marked as \"bad\" and excluded from subsequent analysis. See :func: mne.preprocssessing.find_bad_channels_maxwell for more information on this procedure. The list of bad channels detected through this procedure will be merged with the list of bad channels already present in the dataset, if any. find_flat_channels_meg : bool \u00b6 Auto-detect \"flat\" channels (i.e. those with unusually low variability) and mark them as bad. find_noisy_channels_meg : bool \u00b6 Auto-detect \"noisy\" channels and mark them as bad.","title":"Bad channel detection"},{"location":"settings/preprocessing/autobads.html#config.find_flat_channels_meg","text":"Auto-detect \"flat\" channels (i.e. those with unusually low variability) and mark them as bad.","title":"find_flat_channels_meg"},{"location":"settings/preprocessing/autobads.html#config.find_noisy_channels_meg","text":"Auto-detect \"noisy\" channels and mark them as bad.","title":"find_noisy_channels_meg"},{"location":"settings/preprocessing/epochs.html","text":"rename_events : dict \u00b6 A dictionary specifying which events in the BIDS dataset to rename upon loading, and before processing begins. Pass an empty dictionary to not perform any renaming. Example Rename audio_left in the BIDS dataset to audio/left in the pipeline: rename_events = { 'audio_left' : 'audio/left' } event_repeated : Literal [ 'error' , 'drop' , 'merge' ] \u00b6 How to handle repeated events. We call events \"repeated\" if more than one event occurred at the exact same time point. Currently, MNE-Python cannot handle this situation gracefully when trying to create epochs, and will throw an error. To only keep the event of that time point (\"first\" here referring to the order that events appear in *_events.tsv ), pass 'drop' . You can also request to create a new type of event by merging repeated events by setting this to 'merge' . Warning The 'merge' option is entirely untested in the MNE BIDS Pipeline as of April 1st, 2021. conditions : Union [ Iterable [ str ], Dict [ str , str ]] \u00b6 The time-locked events based on which to create evoked responses. This can either be name of the experimental condition as specified in the BIDS *_events.tsv file; or the name of condition groups , if the condition names contain the (MNE-specific) group separator, / . See the Subselecting epochs tutorial for more information. Passing a dictionary allows to assign a name to map a complex condition name (value) to a more legible one (value). This is a required parameter in the configuration file. If left as None , it will raise an error. Example Specifying conditions as lists of strings: conditions = [ 'auditory/left' , 'visual/left' ] conditions = [ 'auditory/left' , 'auditory/right' ] conditions = [ 'auditory' ] # All \"auditory\" conditions (left AND right) conditions = [ 'auditory' , 'visual' ] conditions = [ 'left' , 'right' ] Pass a dictionary to define a mapping: ```python conditions = {'simple_name': 'complex/condition/with_subconditions'} conditions = {'correct': 'response/correct', 'incorrect': 'response/incorrect'} epochs_tmin : float \u00b6 The beginning of an epoch, relative to the respective event, in seconds. Example epochs_tmin = - 0.2 # 200 ms before event onset epochs_tmax : float \u00b6 The end of an epoch, relative to the respective event, in seconds. Example epochs_tmax = 0.5 # 500 ms after event onset baseline : Optional [ Tuple [ Union [ float , NoneType ], Union [ float , NoneType ]]] \u00b6 Specifies which time interval to use for baseline correction of epochs; if None , no baseline correction is applied. Example baseline = ( None , 0 ) # beginning of epoch until time point zero epochs_metadata_tmin : Optional [ float ] \u00b6 The beginning of the time window for metadata generation, in seconds, relative to the time-locked event of the respective epoch. This may be less than or larger than the epoch's first time point. If None , use the first time point of the epoch. epochs_metadata_tmax : Optional [ float ] \u00b6 Same as epochs_metadata_tmin , but specifying the end of the time window for metadata generation. epochs_metadata_keep_first : Optional [ Iterable [ str ]] \u00b6 Event groupings using hierarchical event descriptors (HEDs) for which to store the time of the first occurrence of any event of this group in a new column with the group name, and the type of that event in a column named after the group, but with a first_ prefix. If None (default), no event aggregation will take place and no new columns will be created. Example Assume you have two response events types, response/left and response/right ; in some trials, both responses occur, because the participant pressed both buttons. Now, you want to keep the first response only. To achieve this, set epochs_metadata_keep_first = [ 'response' ] This will add two new columns to the metadata: response , indicating the time relative to the time-locked event; and first_response , depicting the type of event ( 'left' or 'right' ). You may also specify a grouping for multiple event types: epochs_metadata_keep_first = [ 'response' , 'stimulus' ] This will add the columns response , first_response , stimulus , and first_stimulus . epochs_metadata_keep_last : Optional [ Iterable [ str ]] \u00b6 Same as epochs_metadata_keep_first , but for keeping the last occurrence of matching event types. The columns indicating the event types will be named with a last_ instead of a first_ prefix.","title":"Epoching"},{"location":"settings/preprocessing/epochs.html#config.rename_events","text":"A dictionary specifying which events in the BIDS dataset to rename upon loading, and before processing begins. Pass an empty dictionary to not perform any renaming. Example Rename audio_left in the BIDS dataset to audio/left in the pipeline: rename_events = { 'audio_left' : 'audio/left' }","title":"rename_events"},{"location":"settings/preprocessing/epochs.html#config.event_repeated","text":"How to handle repeated events. We call events \"repeated\" if more than one event occurred at the exact same time point. Currently, MNE-Python cannot handle this situation gracefully when trying to create epochs, and will throw an error. To only keep the event of that time point (\"first\" here referring to the order that events appear in *_events.tsv ), pass 'drop' . You can also request to create a new type of event by merging repeated events by setting this to 'merge' . Warning The 'merge' option is entirely untested in the MNE BIDS Pipeline as of April 1st, 2021.","title":"event_repeated"},{"location":"settings/preprocessing/epochs.html#config.conditions","text":"The time-locked events based on which to create evoked responses. This can either be name of the experimental condition as specified in the BIDS *_events.tsv file; or the name of condition groups , if the condition names contain the (MNE-specific) group separator, / . See the Subselecting epochs tutorial for more information. Passing a dictionary allows to assign a name to map a complex condition name (value) to a more legible one (value). This is a required parameter in the configuration file. If left as None , it will raise an error. Example Specifying conditions as lists of strings: conditions = [ 'auditory/left' , 'visual/left' ] conditions = [ 'auditory/left' , 'auditory/right' ] conditions = [ 'auditory' ] # All \"auditory\" conditions (left AND right) conditions = [ 'auditory' , 'visual' ] conditions = [ 'left' , 'right' ] Pass a dictionary to define a mapping: ```python conditions = {'simple_name': 'complex/condition/with_subconditions'} conditions = {'correct': 'response/correct', 'incorrect': 'response/incorrect'}","title":"conditions"},{"location":"settings/preprocessing/epochs.html#config.epochs_tmin","text":"The beginning of an epoch, relative to the respective event, in seconds. Example epochs_tmin = - 0.2 # 200 ms before event onset","title":"epochs_tmin"},{"location":"settings/preprocessing/epochs.html#config.epochs_tmax","text":"The end of an epoch, relative to the respective event, in seconds. Example epochs_tmax = 0.5 # 500 ms after event onset","title":"epochs_tmax"},{"location":"settings/preprocessing/epochs.html#config.baseline","text":"Specifies which time interval to use for baseline correction of epochs; if None , no baseline correction is applied. Example baseline = ( None , 0 ) # beginning of epoch until time point zero","title":"baseline"},{"location":"settings/preprocessing/epochs.html#config.epochs_metadata_tmin","text":"The beginning of the time window for metadata generation, in seconds, relative to the time-locked event of the respective epoch. This may be less than or larger than the epoch's first time point. If None , use the first time point of the epoch.","title":"epochs_metadata_tmin"},{"location":"settings/preprocessing/epochs.html#config.epochs_metadata_tmax","text":"Same as epochs_metadata_tmin , but specifying the end of the time window for metadata generation.","title":"epochs_metadata_tmax"},{"location":"settings/preprocessing/epochs.html#config.epochs_metadata_keep_first","text":"Event groupings using hierarchical event descriptors (HEDs) for which to store the time of the first occurrence of any event of this group in a new column with the group name, and the type of that event in a column named after the group, but with a first_ prefix. If None (default), no event aggregation will take place and no new columns will be created. Example Assume you have two response events types, response/left and response/right ; in some trials, both responses occur, because the participant pressed both buttons. Now, you want to keep the first response only. To achieve this, set epochs_metadata_keep_first = [ 'response' ] This will add two new columns to the metadata: response , indicating the time relative to the time-locked event; and first_response , depicting the type of event ( 'left' or 'right' ). You may also specify a grouping for multiple event types: epochs_metadata_keep_first = [ 'response' , 'stimulus' ] This will add the columns response , first_response , stimulus , and first_stimulus .","title":"epochs_metadata_keep_first"},{"location":"settings/preprocessing/epochs.html#config.epochs_metadata_keep_last","text":"Same as epochs_metadata_keep_first , but for keeping the last occurrence of matching event types. The columns indicating the event types will be named with a last_ instead of a first_ prefix.","title":"epochs_metadata_keep_last"},{"location":"settings/preprocessing/filter.html","text":"It is typically better to set your filtering properties on the raw data so as to avoid what we call border (or edge) effects. If you use this pipeline for evoked responses, you could consider a low-pass filter cut-off of h_freq = 40 Hz and possibly a high-pass filter cut-off of l_freq = 1 Hz so you would preserve only the power in the 1Hz to 40 Hz band. Note that highpass filtering is not necessarily recommended as it can distort waveforms of evoked components, or simply wash out any low frequency that can may contain brain signal. It can also act as a replacement for baseline correction in Epochs. See below. If you use this pipeline for time-frequency analysis, a default filtering coult be a high-pass filter cut-off of l_freq = 1 Hz a low-pass filter cut-off of h_freq = 120 Hz so you would preserve only the power in the 1Hz to 120 Hz band. If you need more fancy analysis, you are already likely past this kind of tips! \ud83d\ude07 l_freq : Optional [ float ] \u00b6 The low-frequency cut-off in the highpass filtering step. Keep it None if no highpass filtering should be applied. h_freq : Optional [ float ] \u00b6 The high-frequency cut-off in the lowpass filtering step. Keep it None if no lowpass filtering should be applied.","title":"Filtering"},{"location":"settings/preprocessing/filter.html#config.l_freq","text":"The low-frequency cut-off in the highpass filtering step. Keep it None if no highpass filtering should be applied.","title":"l_freq"},{"location":"settings/preprocessing/filter.html#config.h_freq","text":"The high-frequency cut-off in the lowpass filtering step. Keep it None if no lowpass filtering should be applied.","title":"h_freq"},{"location":"settings/preprocessing/maxfilter.html","text":"use_maxwell_filter : bool \u00b6 Whether or not to use Maxwell filtering to preprocess the data. Warning If the data were recorded with internal active compensation (MaxShield), they need to be run through Maxwell filter to avoid distortions. Bad channels need to be set through BIDS channels.tsv and / or via the find_flat_channels_meg and find_noisy_channels_meg options above before applying Maxwell filter. mf_st_duration : Optional [ float ] \u00b6 There are two kinds of maxfiltering: SSS (signal space separation) and tSSS (temporal signal space separation) (see Taulu et al., 2004 ). If not None, apply spatiotemporal SSS (tSSS) with specified buffer duration (in seconds). MaxFilter\u2122's default is 10.0 seconds in v2.2. Spatiotemporal SSS acts as implicitly as a high-pass filter where the cut-off frequency is 1/st_dur Hz. For this (and other) reasons, longer buffers are generally better as long as your system can handle the higher memory usage. To ensure that each window is processed identically, choose a buffer length that divides evenly into your data. Any data at the trailing edge that doesn't fit evenly into a whole buffer window will be lumped into the previous buffer. Good Practice / Advice If you are interested in low frequency activity (<0.1Hz), avoid using tSSS and set mf_st_duration to None . If you are interested in low frequency above 0.1 Hz, you can use the default mf_st_duration to 10 s, meaning it acts like a 0.1 Hz high-pass filter. Example mf_st_duration = None mf_st_duration = 10. # to apply tSSS with 0.1Hz highpass filter. mf_head_origin \u00b6 mf_head_origin : array-like, shape (3,) | 'auto' Origin of internal and external multipolar moment space in meters. If 'auto', it will be estimated from headshape points. If automatic fitting fails (e.g., due to having too few digitization points), consider separately calling the fitting function with different options or specifying the origin manually. Example mf_head_origin = 'auto' mf_reference_run : Optional [ str ] \u00b6 Despite all possible care to avoid movements in the MEG, the participant will likely slowly drift down from the Dewar or slightly shift the head around in the course of the recording session. Hence, to take this into account, we are realigning all data to a single position. For this, you need to define a reference run (typically the one in the middle of the recording session). Which run to take as the reference for adjusting the head position of all runs. If None , pick the first run. Example mf_reference_run = '01' # Use run \"01\" mf_cal_fname : Optional [ str ] \u00b6 Warning This parameter should only be used for BIDS datasets that don't store the fine-calibration file according to BIDS . Path to the Maxwell Filter calibration file. If None the recommended location is used. Example mf_cal_fname = '/path/to/your/file/calibration_cal.dat' mf_ctc_fname : Optional [ str ] \u00b6 Path to the Maxwell Filter cross-talk file. If None the recommended location is used. Warning This parameter should only be used for BIDS datasets that don't store the cross-talk file according to BIDS . Example mf_ctc_fname = '/path/to/your/file/crosstalk_ct.fif'","title":"Maxwell filter"},{"location":"settings/preprocessing/maxfilter.html#config.use_maxwell_filter","text":"Whether or not to use Maxwell filtering to preprocess the data. Warning If the data were recorded with internal active compensation (MaxShield), they need to be run through Maxwell filter to avoid distortions. Bad channels need to be set through BIDS channels.tsv and / or via the find_flat_channels_meg and find_noisy_channels_meg options above before applying Maxwell filter.","title":"use_maxwell_filter"},{"location":"settings/preprocessing/maxfilter.html#config.mf_st_duration","text":"There are two kinds of maxfiltering: SSS (signal space separation) and tSSS (temporal signal space separation) (see Taulu et al., 2004 ). If not None, apply spatiotemporal SSS (tSSS) with specified buffer duration (in seconds). MaxFilter\u2122's default is 10.0 seconds in v2.2. Spatiotemporal SSS acts as implicitly as a high-pass filter where the cut-off frequency is 1/st_dur Hz. For this (and other) reasons, longer buffers are generally better as long as your system can handle the higher memory usage. To ensure that each window is processed identically, choose a buffer length that divides evenly into your data. Any data at the trailing edge that doesn't fit evenly into a whole buffer window will be lumped into the previous buffer. Good Practice / Advice If you are interested in low frequency activity (<0.1Hz), avoid using tSSS and set mf_st_duration to None . If you are interested in low frequency above 0.1 Hz, you can use the default mf_st_duration to 10 s, meaning it acts like a 0.1 Hz high-pass filter. Example mf_st_duration = None mf_st_duration = 10. # to apply tSSS with 0.1Hz highpass filter.","title":"mf_st_duration"},{"location":"settings/preprocessing/maxfilter.html#config.mf_head_origin","text":"mf_head_origin : array-like, shape (3,) | 'auto' Origin of internal and external multipolar moment space in meters. If 'auto', it will be estimated from headshape points. If automatic fitting fails (e.g., due to having too few digitization points), consider separately calling the fitting function with different options or specifying the origin manually. Example mf_head_origin = 'auto'","title":"mf_head_origin"},{"location":"settings/preprocessing/maxfilter.html#config.mf_reference_run","text":"Despite all possible care to avoid movements in the MEG, the participant will likely slowly drift down from the Dewar or slightly shift the head around in the course of the recording session. Hence, to take this into account, we are realigning all data to a single position. For this, you need to define a reference run (typically the one in the middle of the recording session). Which run to take as the reference for adjusting the head position of all runs. If None , pick the first run. Example mf_reference_run = '01' # Use run \"01\"","title":"mf_reference_run"},{"location":"settings/preprocessing/maxfilter.html#config.mf_cal_fname","text":"Warning This parameter should only be used for BIDS datasets that don't store the fine-calibration file according to BIDS . Path to the Maxwell Filter calibration file. If None the recommended location is used. Example mf_cal_fname = '/path/to/your/file/calibration_cal.dat'","title":"mf_cal_fname"},{"location":"settings/preprocessing/maxfilter.html#config.mf_ctc_fname","text":"Path to the Maxwell Filter cross-talk file. If None the recommended location is used. Warning This parameter should only be used for BIDS datasets that don't store the cross-talk file according to BIDS . Example mf_ctc_fname = '/path/to/your/file/crosstalk_ct.fif'","title":"mf_ctc_fname"},{"location":"settings/preprocessing/resample.html","text":"If you have acquired data with a very high sampling frequency (e.g. 2 kHz) you will likely want to downsample to lighten up the size of the files you are working with (pragmatics) If you are interested in typical analysis (up to 120 Hz) you can typically resample your data down to 500 Hz without preventing reliable time-frequency exploration of your data. resample_sfreq : Optional [ float ] \u00b6 Specifies at which sampling frequency the data should be resampled. If None then no resampling will be done. Example resample_sfreq = None # no resampling resample_sfreq = 500 # resample to 500Hz decim : int \u00b6 Says how much to decimate data at the epochs level. It is typically an alternative to the resample_sfreq parameter that can be used for resampling raw data. 1 means no decimation. Good Practice / Advice Decimation requires to lowpass filtered the data to avoid aliasing. Note that using decimation is much faster than resampling. Example decim = 1 # no decimation decim = 4 # decimate by 4 ie devide sampling frequency by 4","title":"Resampling"},{"location":"settings/preprocessing/resample.html#config.resample_sfreq","text":"Specifies at which sampling frequency the data should be resampled. If None then no resampling will be done. Example resample_sfreq = None # no resampling resample_sfreq = 500 # resample to 500Hz","title":"resample_sfreq"},{"location":"settings/preprocessing/resample.html#config.decim","text":"Says how much to decimate data at the epochs level. It is typically an alternative to the resample_sfreq parameter that can be used for resampling raw data. 1 means no decimation. Good Practice / Advice Decimation requires to lowpass filtered the data to avoid aliasing. Note that using decimation is much faster than resampling. Example decim = 1 # no decimation decim = 4 # decimate by 4 ie devide sampling frequency by 4","title":"decim"},{"location":"settings/preprocessing/ssp_ica.html","text":"spatial_filter : Optional [ Literal [ 'ssp' , 'ica' ]] \u00b6 Whether to use a spatial filter to detect and remove artifacts. The BIDS Pipeline offers the use of signal-space projection (SSP) and independent component analysis (ICA). Use 'ssp' for SSP, 'ica' for ICA, and None if you do not wish to apply a spatial filter for artifact removal. The Pipeline will try to automatically discover EOG and ECG artifacts. For SSP, it will then produce projection vectors that remove (\"project out\") these artifacts from the data. For ICA, the independent components related to EOG and ECG activity will be omitted during the signal reconstruction step in order to remove the artifacts. The ICA procedure can be configured in various ways using the configuration options you can find below. ica_reject : Optional [ Dict [ str , float ]] \u00b6 Peak-to-peak amplitude limits to exclude epochs from ICA fitting. This allows you to remove strong transient artifacts, which could negatively affect ICA performance. The BIDS Pipeline will automatically try to detect EOG and ECG artifacts in your data, and remove them. For this to work properly, it is recommended to not specify rejection thresholds for EOG and ECG channels here \u2013 otherwise, ICA won't be able to \"see\" these artifacts. Example ica_reject = { 'grad' : 10e-10 , 'mag' : 20e-12 , 'eeg' : 400e-6 } ica_reject = { 'grad' : 15e-10 } ica_reject = None ica_algorithm : Literal [ 'picard' , 'fastica' , 'extended_infomax' ] \u00b6 The ICA algorithm to use. ica_l_freq : Optional [ float ] \u00b6 The cutoff frequency of the high-pass filter to apply before running ICA. Using a relatively high cutoff like 1 Hz will remove slow drifts from the data, yielding improved ICA results. Must be set to 1 Hz or above. Set to None to not apply an additional high-pass filter. Note The filter will be applied to raw data which was already filtered according to the l_freq and h_freq settings. After filtering, the data will be epoched, and the epochs will be submitted to ICA. Info The Pipeline will only allow you to perform ICA on data that has been high-pass filtered with a 1 Hz cutoff or higher. This is a conscious, opinionated (but partially data-driven) decision made by the developers. If you have reason to challenge this behavior, please get in touch with us so we can discuss. ica_max_iterations : int \u00b6 Maximum number of iterations to decompose the data into independent components. A low number means to finish earlier, but the consequence is that the algorithm may not have finished converging. To ensure convergence, pick a high number here (e.g. 3000); yet the algorithm will terminate as soon as it determines that is has successfully converged, and not necessarily exhaust the maximum number of iterations. Note that the default of 200 seems to be sufficient for Picard in many datasets, because it converges quicker than the other algorithms; but e.g. for FastICA, this limit may be too low to achieve convergence. ica_n_components : Union [ float , int ] \u00b6 MNE conducts ICA as a sort of a two-step procedure: First, a PCA is run on the data (trying to exclude zero-valued components in rank-deficient data); and in the second step, the principal componenets are passed to the actual ICA. You can select how many of the total principal components to pass to ICA \u2013 it can be all or just a subset. This determines how many independent components to fit, and can be controlled via this setting. If int, specifies the number of principal components that are passed to the ICA algorithm, which will be the number of independent components to fit. It must not be greater than the rank of your data (which is typically the number of channels, but may be less in some cases). If float between 0 and 1, all principal components with cumulative explained variance less than the value specified here will be passed to ICA. If None , all principal components will be used. This setting may drastically alter the time required to compute ICA. ica_decim : Optional [ int ] \u00b6 The decimation parameter to compute ICA. If 5 it means that 1 every 5 sample is used by ICA solver. The higher the faster it is to run but the less data you have to compute a good ICA. Set to 1 or None to not perform any decimation. ica_ctps_ecg_threshold : float \u00b6 The threshold parameter passed to find_bads_ecg method. ica_eog_threshold : float \u00b6 The threshold to use during automated EOG classification. Lower values mean that more ICs will be identified as EOG-related. If too low, the false-alarm rate increases dramatically.","title":"SSP & ICA"},{"location":"settings/preprocessing/ssp_ica.html#config.spatial_filter","text":"Whether to use a spatial filter to detect and remove artifacts. The BIDS Pipeline offers the use of signal-space projection (SSP) and independent component analysis (ICA). Use 'ssp' for SSP, 'ica' for ICA, and None if you do not wish to apply a spatial filter for artifact removal. The Pipeline will try to automatically discover EOG and ECG artifacts. For SSP, it will then produce projection vectors that remove (\"project out\") these artifacts from the data. For ICA, the independent components related to EOG and ECG activity will be omitted during the signal reconstruction step in order to remove the artifacts. The ICA procedure can be configured in various ways using the configuration options you can find below.","title":"spatial_filter"},{"location":"settings/preprocessing/ssp_ica.html#config.ica_reject","text":"Peak-to-peak amplitude limits to exclude epochs from ICA fitting. This allows you to remove strong transient artifacts, which could negatively affect ICA performance. The BIDS Pipeline will automatically try to detect EOG and ECG artifacts in your data, and remove them. For this to work properly, it is recommended to not specify rejection thresholds for EOG and ECG channels here \u2013 otherwise, ICA won't be able to \"see\" these artifacts. Example ica_reject = { 'grad' : 10e-10 , 'mag' : 20e-12 , 'eeg' : 400e-6 } ica_reject = { 'grad' : 15e-10 } ica_reject = None","title":"ica_reject"},{"location":"settings/preprocessing/ssp_ica.html#config.ica_algorithm","text":"The ICA algorithm to use.","title":"ica_algorithm"},{"location":"settings/preprocessing/ssp_ica.html#config.ica_l_freq","text":"The cutoff frequency of the high-pass filter to apply before running ICA. Using a relatively high cutoff like 1 Hz will remove slow drifts from the data, yielding improved ICA results. Must be set to 1 Hz or above. Set to None to not apply an additional high-pass filter. Note The filter will be applied to raw data which was already filtered according to the l_freq and h_freq settings. After filtering, the data will be epoched, and the epochs will be submitted to ICA. Info The Pipeline will only allow you to perform ICA on data that has been high-pass filtered with a 1 Hz cutoff or higher. This is a conscious, opinionated (but partially data-driven) decision made by the developers. If you have reason to challenge this behavior, please get in touch with us so we can discuss.","title":"ica_l_freq"},{"location":"settings/preprocessing/ssp_ica.html#config.ica_max_iterations","text":"Maximum number of iterations to decompose the data into independent components. A low number means to finish earlier, but the consequence is that the algorithm may not have finished converging. To ensure convergence, pick a high number here (e.g. 3000); yet the algorithm will terminate as soon as it determines that is has successfully converged, and not necessarily exhaust the maximum number of iterations. Note that the default of 200 seems to be sufficient for Picard in many datasets, because it converges quicker than the other algorithms; but e.g. for FastICA, this limit may be too low to achieve convergence.","title":"ica_max_iterations"},{"location":"settings/preprocessing/ssp_ica.html#config.ica_n_components","text":"MNE conducts ICA as a sort of a two-step procedure: First, a PCA is run on the data (trying to exclude zero-valued components in rank-deficient data); and in the second step, the principal componenets are passed to the actual ICA. You can select how many of the total principal components to pass to ICA \u2013 it can be all or just a subset. This determines how many independent components to fit, and can be controlled via this setting. If int, specifies the number of principal components that are passed to the ICA algorithm, which will be the number of independent components to fit. It must not be greater than the rank of your data (which is typically the number of channels, but may be less in some cases). If float between 0 and 1, all principal components with cumulative explained variance less than the value specified here will be passed to ICA. If None , all principal components will be used. This setting may drastically alter the time required to compute ICA.","title":"ica_n_components"},{"location":"settings/preprocessing/ssp_ica.html#config.ica_decim","text":"The decimation parameter to compute ICA. If 5 it means that 1 every 5 sample is used by ICA solver. The higher the faster it is to run but the less data you have to compute a good ICA. Set to 1 or None to not perform any decimation.","title":"ica_decim"},{"location":"settings/preprocessing/ssp_ica.html#config.ica_ctps_ecg_threshold","text":"The threshold parameter passed to find_bads_ecg method.","title":"ica_ctps_ecg_threshold"},{"location":"settings/preprocessing/ssp_ica.html#config.ica_eog_threshold","text":"The threshold to use during automated EOG classification. Lower values mean that more ICs will be identified as EOG-related. If too low, the false-alarm rate increases dramatically.","title":"ica_eog_threshold"},{"location":"settings/preprocessing/stim_artifact.html","text":"When using electric stimulation systems, e.g. for median nerve or index stimulation, it is frequent to have a stimulation artifact. This option allows to fix it by linear interpolation early in the pipeline on the raw data. fix_stim_artifact : bool \u00b6 Apply interpolation to fix stimulation artifact. Example fix_stim_artifact = False stim_artifact_tmin : float \u00b6 Start time of the interpolation window in seconds. Example stim_artifact_tmin = 0. # on stim onset stim_artifact_tmax : float \u00b6 End time of the interpolation window in seconds. Example stim_artifact_tmax = 0.01 # up to 10ms post-stimulation","title":"Stimulation artifact"},{"location":"settings/preprocessing/stim_artifact.html#config.fix_stim_artifact","text":"Apply interpolation to fix stimulation artifact. Example fix_stim_artifact = False","title":"fix_stim_artifact"},{"location":"settings/preprocessing/stim_artifact.html#config.stim_artifact_tmin","text":"Start time of the interpolation window in seconds. Example stim_artifact_tmin = 0. # on stim onset","title":"stim_artifact_tmin"},{"location":"settings/preprocessing/stim_artifact.html#config.stim_artifact_tmax","text":"End time of the interpolation window in seconds. Example stim_artifact_tmax = 0.01 # up to 10ms post-stimulation","title":"stim_artifact_tmax"},{"location":"settings/sensor/statistics.html","text":"contrasts : Iterable [ Tuple [ str , str ]] \u00b6 The conditions to contrast via a subtraction of ERPs / ERFs. Each tuple in the list corresponds to one contrast. The condition names must be specified in conditions above. Pass an empty list to avoid calculation of contrasts. Example Contrast the \"left\" and the \"right\" conditions by calculating left - right at every time point of the evoked responses: conditions = [ 'left' , 'right' ] contrasts = [( 'left' , 'right' )] # Note we pass a tuple inside the list! Contrast the \"left\" and the \"right\" conditions within the \"auditory\" and the \"visual\" modality, and \"auditory\" vs \"visual\" regardless of side: conditions = [ 'auditory/left' , 'auditory/right' , 'visual/left' , 'visual/right' ] contrasts = [( 'auditory/left' , 'auditory/right' ), ( 'visual/left' , 'visual/right' ), ( 'auditory' , 'visual' )] decode : bool \u00b6 Whether to perform decoding (MVPA) on the contrasts specified above as \"contrasts\". MVPA will be performed on the level of individual epochs. decoding_metric : str \u00b6 The metric to use for cross-validation. It can be 'roc_auc' or 'accuracy' or any other metric supported by scikit-learn . With AUC, chance level is the same regardless of class balance. decoding_n_splits : int \u00b6 The number of folds (a.k.a. splits) to use in the cross-validation. n_boot : int \u00b6 The number of bootstrap resamples when estimating the standard error and confidence interval of the mean decoding score.","title":"Statistics"},{"location":"settings/sensor/statistics.html#config.contrasts","text":"The conditions to contrast via a subtraction of ERPs / ERFs. Each tuple in the list corresponds to one contrast. The condition names must be specified in conditions above. Pass an empty list to avoid calculation of contrasts. Example Contrast the \"left\" and the \"right\" conditions by calculating left - right at every time point of the evoked responses: conditions = [ 'left' , 'right' ] contrasts = [( 'left' , 'right' )] # Note we pass a tuple inside the list! Contrast the \"left\" and the \"right\" conditions within the \"auditory\" and the \"visual\" modality, and \"auditory\" vs \"visual\" regardless of side: conditions = [ 'auditory/left' , 'auditory/right' , 'visual/left' , 'visual/right' ] contrasts = [( 'auditory/left' , 'auditory/right' ), ( 'visual/left' , 'visual/right' ), ( 'auditory' , 'visual' )]","title":"contrasts"},{"location":"settings/sensor/statistics.html#config.decode","text":"Whether to perform decoding (MVPA) on the contrasts specified above as \"contrasts\". MVPA will be performed on the level of individual epochs.","title":"decode"},{"location":"settings/sensor/statistics.html#config.decoding_metric","text":"The metric to use for cross-validation. It can be 'roc_auc' or 'accuracy' or any other metric supported by scikit-learn . With AUC, chance level is the same regardless of class balance.","title":"decoding_metric"},{"location":"settings/sensor/statistics.html#config.decoding_n_splits","text":"The number of folds (a.k.a. splits) to use in the cross-validation.","title":"decoding_n_splits"},{"location":"settings/sensor/statistics.html#config.n_boot","text":"The number of bootstrap resamples when estimating the standard error and confidence interval of the mean decoding score.","title":"n_boot"},{"location":"settings/sensor/time_freq.html","text":"time_frequency_conditions : Iterable [ str ] \u00b6 The conditions to compute time-frequency decomposition on. Example time_frequency_conditions = [ 'left' , 'right' ]","title":"Time-frequency analysis"},{"location":"settings/sensor/time_freq.html#config.time_frequency_conditions","text":"The conditions to compute time-frequency decomposition on. Example time_frequency_conditions = [ 'left' , 'right' ]","title":"time_frequency_conditions"},{"location":"settings/source/bem.html","text":"bem_mri_images : Literal [ 'FLASH' , 'T1' , 'auto' ] \u00b6 Which types of MRI images to use when creating the BEM model. If 'FLASH' , use FLASH MRI images, and raise an exception if they cannot be found. Advice It is recommended to use the FLASH images if available, as the quality of the extracted BEM surfaces will be higher. If 'T1' , create the BEM surfaces from the T1-weighted images using the watershed algorithm. If 'auto' , use FLASH images if available, and use the watershed algorithm with the T1-weighted images otherwise. recreate_bem : bool \u00b6 Whether to re-create the BEM surfaces, even if existing surfaces have been found. If False , the BEM surfaces are only created if they do not exist already. True forces their recreation, overwriting existing BEM surfaces.","title":"BEM surface"},{"location":"settings/source/bem.html#config.bem_mri_images","text":"Which types of MRI images to use when creating the BEM model. If 'FLASH' , use FLASH MRI images, and raise an exception if they cannot be found. Advice It is recommended to use the FLASH images if available, as the quality of the extracted BEM surfaces will be higher. If 'T1' , create the BEM surfaces from the T1-weighted images using the watershed algorithm. If 'auto' , use FLASH images if available, and use the watershed algorithm with the T1-weighted images otherwise.","title":"bem_mri_images"},{"location":"settings/source/bem.html#config.recreate_bem","text":"Whether to re-create the BEM surfaces, even if existing surfaces have been found. If False , the BEM surfaces are only created if they do not exist already. True forces their recreation, overwriting existing BEM surfaces.","title":"recreate_bem"},{"location":"settings/source/forward.html","text":"mri_t1_path_generator : Optional [ Callable ] \u00b6 To perform source-level analyses, the Pipeline needs to generate a transformation matrix that translates coordinates from MEG and EEG sensor space to MRI space, and vice versa. This process, called \"coregistration\", requires access to both, the electrophyisiological recordings as well as T1-weighted MRI images of the same participant. If both are stored within the same session, the Pipeline (or, more specifically, MNE-BIDS) can find the respective files automatically. However, in certain situations, this is not possible. Examples include: MRI was conducted during a different session than the electrophysiological recording. MRI was conducted in a single session, while electrophysiological recordings spanned across several sessions. MRI and electrophysiological data are stored in separate BIDS datasets to allow easier storage and distribution in certain situations. To allow the Pipeline to find the correct MRI images and perform coregistration automatically, we provide a \"hook\" that allows you to provide in a custom function whose output tells the Pipeline where to find the T1-weighted image. The function is expected to accept a single parameter. The Pipeline will pass a BIDSPath with the following parameters set based on the currently processed electrophysiological data: the subject ID, BIDSPath.subject the experimental session, BIDSPath.session the BIDS root, BIDSPath.root This BIDSPath can then be modified \u2013 or an entirely new BIDSPath can be generated \u2013 and returned by the function, pointing to the T1-weighted image. Note The function accepts and returns a single BIDSPath . Example The MRI session is different than the electrophysiological session: def get_t1_from_meeg ( bids_path ): bids_path . session = 'MRI' return bids_path mri_t1_path_generator = get_t1_from_meeg The MRI recording is stored in a different BIDS dataset than the electrophysiological data: def get_t1_from_meeg ( bids_path ): bids_path . root = '/data/mri' return bids_path mri_t1_path_generator = get_t1_from_meeg spacing : Union [ Literal [ 'oct5' , 'oct6' , 'ico4' , 'ico5' , 'all' ], int ] \u00b6 The spacing to use. Can be 'ico#' for a recursively subdivided icosahedron, 'oct#' for a recursively subdivided octahedron, 'all' for all points, or an integer to use approximate distance-based spacing (in mm). See (the respective MNE-Python documentation) [https://mne.tools/dev/overview/cookbook.html#setting-up-the-source-space] for more info. mindist : float \u00b6 Exclude points closer than this distance (mm) to the bounding surface.","title":"Source space & forward solution"},{"location":"settings/source/forward.html#config.mri_t1_path_generator","text":"To perform source-level analyses, the Pipeline needs to generate a transformation matrix that translates coordinates from MEG and EEG sensor space to MRI space, and vice versa. This process, called \"coregistration\", requires access to both, the electrophyisiological recordings as well as T1-weighted MRI images of the same participant. If both are stored within the same session, the Pipeline (or, more specifically, MNE-BIDS) can find the respective files automatically. However, in certain situations, this is not possible. Examples include: MRI was conducted during a different session than the electrophysiological recording. MRI was conducted in a single session, while electrophysiological recordings spanned across several sessions. MRI and electrophysiological data are stored in separate BIDS datasets to allow easier storage and distribution in certain situations. To allow the Pipeline to find the correct MRI images and perform coregistration automatically, we provide a \"hook\" that allows you to provide in a custom function whose output tells the Pipeline where to find the T1-weighted image. The function is expected to accept a single parameter. The Pipeline will pass a BIDSPath with the following parameters set based on the currently processed electrophysiological data: the subject ID, BIDSPath.subject the experimental session, BIDSPath.session the BIDS root, BIDSPath.root This BIDSPath can then be modified \u2013 or an entirely new BIDSPath can be generated \u2013 and returned by the function, pointing to the T1-weighted image. Note The function accepts and returns a single BIDSPath . Example The MRI session is different than the electrophysiological session: def get_t1_from_meeg ( bids_path ): bids_path . session = 'MRI' return bids_path mri_t1_path_generator = get_t1_from_meeg The MRI recording is stored in a different BIDS dataset than the electrophysiological data: def get_t1_from_meeg ( bids_path ): bids_path . root = '/data/mri' return bids_path mri_t1_path_generator = get_t1_from_meeg","title":"mri_t1_path_generator"},{"location":"settings/source/forward.html#config.spacing","text":"The spacing to use. Can be 'ico#' for a recursively subdivided icosahedron, 'oct#' for a recursively subdivided octahedron, 'all' for all points, or an integer to use approximate distance-based spacing (in mm). See (the respective MNE-Python documentation) [https://mne.tools/dev/overview/cookbook.html#setting-up-the-source-space] for more info.","title":"spacing"},{"location":"settings/source/forward.html#config.mindist","text":"Exclude points closer than this distance (mm) to the bounding surface.","title":"mindist"},{"location":"settings/source/general.html","text":"run_source_estimation : bool \u00b6 Whether to run source estimation processing steps if not explicitly requested.","title":"General settings"},{"location":"settings/source/general.html#config.run_source_estimation","text":"Whether to run source estimation processing steps if not explicitly requested.","title":"run_source_estimation"},{"location":"settings/source/inverse.html","text":"inverse_method : Literal [ 'MNE' , 'dSPM' , 'sLORETA' , 'eLORETA' ] \u00b6 Use minimum norm, dSPM (default), sLORETA, or eLORETA to calculate the inverse solution. noise_cov : Optional [ Tuple [ Union [ float , NoneType ], Union [ float ]], Literal [ 'emptyroom' ]] \u00b6 Specify how to estimate the noise covariance matrix, which is used in inverse modeling. If a tuple, it takes the form (tmin, tmax) with the time specified in seconds. If the first value of the tuple is None , the considered period starts at the beginning of the epoch. If the second value of the tuple is None , the considered period ends at the end of the epoch. The default, (None, 0) , includes the entire period before the event, which is typically the pre-stimulus period. If emptyroom , the noise covariance matrix will be estimated from an empty-room MEG recording. The empty-room recording will be automatically selected based on recording date and time. Please note that when processing data that contains EEG channels, the noise covariance can ONLY be estimated from the pre-stimulus period. Example Use the period from start of the epoch until 100 ms before the experimental event: noise_cov = ( None , - 0.1 ) Use the time period from the experimental event until the end of the epoch: noise_cov = ( 0 , None ) Use an empty-room recording: noise_cov = 'emptyroom'","title":"Inverse solution"},{"location":"settings/source/inverse.html#config.inverse_method","text":"Use minimum norm, dSPM (default), sLORETA, or eLORETA to calculate the inverse solution.","title":"inverse_method"},{"location":"settings/source/inverse.html#config.noise_cov","text":"Specify how to estimate the noise covariance matrix, which is used in inverse modeling. If a tuple, it takes the form (tmin, tmax) with the time specified in seconds. If the first value of the tuple is None , the considered period starts at the beginning of the epoch. If the second value of the tuple is None , the considered period ends at the end of the epoch. The default, (None, 0) , includes the entire period before the event, which is typically the pre-stimulus period. If emptyroom , the noise covariance matrix will be estimated from an empty-room MEG recording. The empty-room recording will be automatically selected based on recording date and time. Please note that when processing data that contains EEG channels, the noise covariance can ONLY be estimated from the pre-stimulus period. Example Use the period from start of the epoch until 100 ms before the experimental event: noise_cov = ( None , - 0.1 ) Use the time period from the experimental event until the end of the epoch: noise_cov = ( 0 , None ) Use an empty-room recording: noise_cov = 'emptyroom'","title":"noise_cov"}]}